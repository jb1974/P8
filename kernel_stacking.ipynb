{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90bff9d0",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce07718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Misc\n",
    "import os\n",
    "import gc\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sound treatments\n",
    "import librosa\n",
    "from scipy import signal\n",
    "import resampy\n",
    "\n",
    "# TRILL\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras.backend as K \n",
    "\n",
    "## Metrics\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.layers.netvlad import NetVLAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e8401",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202c5949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inactivate warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f27839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = '/kaggle/input/birdclef-2022/'\n",
    "#WORKING_PATH = '/kaggle/working/'\n",
    "#TRILL_PATH = '/kaggle/input/ziptrill/'\n",
    "#VGGISH_PATH = '/kaggle/input/vggishfull/'\n",
    "#MODEL_PATH = '/kaggle/input/models/'\n",
    "\n",
    "DATA_PATH = './data/'\n",
    "WORKING_PATH = './working/stacking/'\n",
    "TRILL_PATH = './working/stacking/trill/'\n",
    "VGGISH_PATH = './working/stacking/'\n",
    "MODEL_PATH = './working/stacking/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0270101",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c081303",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scored_birds = ['akiapo', 'aniani', 'apapan', 'barpet', 'crehon',\n",
    "                'elepai', 'ercfra', 'hawama', 'hawcre', 'hawgoo',\n",
    "                'hawhaw', 'hawpet1', 'houfin', 'iiwi', 'jabwar',\n",
    "                'maupar', 'omao', 'puaioh', 'skylar', 'warwhe1',\n",
    "                'yefcan']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16bad5c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4447ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(model_name):\n",
    "    if model_name == 'trill':\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.Input((80000,)))\n",
    "\n",
    "        trill_layer = hub.KerasLayer(\n",
    "            handle=TRILL_PATH,\n",
    "            trainable=False,\n",
    "            arguments={'sample_rate': int(16000)},\n",
    "            output_key='embedding',\n",
    "            output_shape=[None, 2048]\n",
    "        )\n",
    "\n",
    "        model.add(trill_layer)\n",
    "        model.add(NetVLAD(num_clusters=8))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(21, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(l=1e-5)))\n",
    "\n",
    "    elif model_name == 'efficientnetb0':\n",
    "        base_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights=None, pooling='avg')\n",
    "        dense = tf.keras.layers.Dense(142, activation='relu')(base_model.output)\n",
    "        outputs = tf.keras.layers.Dense(21, activation='sigmoid')(dense)\n",
    "        base_model.trainable = False\n",
    "        model = tf.keras.models.Model(inputs=base_model.input, outputs=outputs)\n",
    "        \n",
    "    elif model_name == 'vggish':\n",
    "        '''base_model, _, _ = vgk.get_embedding_model(hop_duration=0.25)   \n",
    "        dense = Dense(128, activation='relu')(base_model.output)\n",
    "        outputs = Dense(21, activation='sigmoid')(dense)      \n",
    "        base_model.trainable = False\n",
    "        model = Model(inputs=base_model.input, outputs=outputs)'''\n",
    "        \n",
    "        model = tf.keras.models.load_model(VGGISH_PATH + 'VGGish_full.h5')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e401a0",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d4a09",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a0aadc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Trill = create_cnn('trill')\n",
    "Trill.load_weights(MODEL_PATH + 'trill.h5')\n",
    "Trill.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=[\n",
    "              tfa.metrics.F1Score(name='f1macro', num_classes=21, average='macro')], run_eagerly=True)\n",
    "Trill.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0a64d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientNetB0 = create_cnn('efficientnetb0')\n",
    "EfficientNetB0.load_weights(MODEL_PATH + 'EfficientNetB0.h5')\n",
    "EfficientNetB0.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=[\n",
    "                       tfa.metrics.F1Score(name='f1macro', num_classes=21, average='macro')], run_eagerly=True)\n",
    "EfficientNetB0.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56399a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGGish = create_cnn('vggish')\n",
    "VGGish.compile(optimizer=tf.keras.optimizers.Adam(), loss='binary_crossentropy', metrics=[\n",
    "               tfa.metrics.F1Score(name='f1macro', num_classes=21, average='macro')], run_eagerly=True)\n",
    "VGGish.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad37c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = joblib.load(MODEL_PATH + 'meta_model.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04c9a2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3540"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del hub\n",
    "del NetVLAD\n",
    "del tfa\n",
    "del joblib\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c16283",
   "metadata": {},
   "source": [
    "## Feature extraxction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2854ae55",
   "metadata": {},
   "source": [
    "### Trill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c41bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sound noise reduction\n",
    "def f_high_trill(y, sr):\n",
    "    b, a = signal.butter(10, 1000/(sr/2), btype='highpass')\n",
    "    yf = signal.lfilter(b, a, y)\n",
    "    return yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b53d4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures_trill(y, sr):\n",
    "    # Sound noise reduction\n",
    "    y = f_high_trill(y, sr)\n",
    "    # Resample\n",
    "    y = librosa.resample(y, sr, 16000)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c65c8",
   "metadata": {},
   "source": [
    "### EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04ef4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conf:\n",
    "    # Preprocessing settings\n",
    "    sampling_rate = 44100\n",
    "    n_mels = 224\n",
    "    hop_length = 494\n",
    "    n_fft = n_mels * 10\n",
    "    fmin = 20\n",
    "    fmax = 16000\n",
    "    \n",
    "    # Model parameters\n",
    "    num_rows = 224\n",
    "    num_columns = 224\n",
    "    num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00667336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_melspectrogram(audio):\n",
    "    spectrogram = librosa.feature.melspectrogram(audio,\n",
    "                                                 sr=conf.sampling_rate,\n",
    "                                                 n_mels=conf.n_mels,\n",
    "                                                 hop_length=conf.hop_length,\n",
    "                                                 n_fft=conf.n_fft,\n",
    "                                                 fmin=conf.fmin,\n",
    "                                                 fmax=conf.fmax)\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "314b178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    Converts a one channel array to a 3 channel one in [0, 255]\n",
    "    Arguments:\n",
    "        X {numpy array [H x W]} -- 2D array to convert\n",
    "    Keyword Arguments:\n",
    "        eps {float} -- To avoid dividing by 0 (default: {1e-6})\n",
    "        mean {None or np array} -- Mean for normalization (default: {None})\n",
    "        std {None or np array} -- Std for normalization (default: {None})\n",
    "    Returns:\n",
    "        numpy array [3 x H x W] -- RGB numpy array\n",
    "    \"\"\"\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    # Normalize to [0, 255]\n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53e469f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures_EfficientNetB0(y, sr):\n",
    "    # Extract features\n",
    "    feat = audio_to_melspectrogram(y)\n",
    "    feat = mono_to_color(feat)\n",
    "    feat = feat.astype(np.uint8)\n",
    "    \n",
    "    # EfficientNet preprocess\n",
    "    feat = tf.keras.applications.efficientnet.preprocess_input(feat)\n",
    "    \n",
    "    X = np.empty((1, conf.num_rows, conf.num_columns, conf.num_channels))\n",
    "    x_features = feat.tolist()\n",
    "    X[0] = np.array(x_features)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa8458",
   "metadata": {},
   "source": [
    "### VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5651795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sound noise reduction\n",
    "def f_high_VGGish(y,sr):\n",
    "    b,a = signal.butter(10, 2000/(sr/2), btype='highpass')\n",
    "    yf = signal.lfilter(b,a,y)\n",
    "    return yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46552579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveform_to_examples(data, sample_rate):\n",
    "    # Convert to mono.\n",
    "    if len(data.shape) > 1:\n",
    "        data = np.mean(data, axis=1)\n",
    "    # Resample to the rate assumed by VGGish.\n",
    "    if sample_rate != 16000:\n",
    "        data = resampy.resample(data, sample_rate, 16000)\n",
    "\n",
    "    # Compute log mel spectrogram features.\n",
    "    log_mel = log_mel_spectrogram(\n",
    "        data,\n",
    "        audio_sample_rate=16000,\n",
    "        log_offset=0.01,\n",
    "        window_length_secs=0.025,\n",
    "        hop_length_secs=0.010,\n",
    "        num_mel_bins=64,\n",
    "        lower_edge_hertz=125,\n",
    "        upper_edge_hertz=7500)\n",
    "\n",
    "    # Frame features into examples.\n",
    "    features_sample_rate = 1.0 / 0.010\n",
    "    example_window_length = int(round(0.96 * features_sample_rate))\n",
    "    example_hop_length = int(round(0.96 * features_sample_rate))\n",
    "    log_mel_examples = frame(\n",
    "        log_mel,\n",
    "        window_length=example_window_length,\n",
    "        hop_length=example_hop_length)\n",
    "    return log_mel_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14f70134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mel_spectrogram(data,\n",
    "                        audio_sample_rate=8000,\n",
    "                        log_offset=0.0,\n",
    "                        window_length_secs=0.025,\n",
    "                        hop_length_secs=0.010,\n",
    "                        **kwargs):\n",
    "    window_length_samples = int(round(audio_sample_rate * window_length_secs))\n",
    "    hop_length_samples = int(round(audio_sample_rate * hop_length_secs))\n",
    "    fft_length = 2 ** int(np.ceil(np.log(window_length_samples) / np.log(2.0)))\n",
    "    spectrogram = stft_magnitude(\n",
    "        data,\n",
    "        fft_length=fft_length,\n",
    "        hop_length=hop_length_samples,\n",
    "        window_length=window_length_samples)\n",
    "    mel_spectrogram = np.dot(spectrogram, spectrogram_to_mel_matrix(\n",
    "        num_spectrogram_bins=spectrogram.shape[1],\n",
    "        audio_sample_rate=audio_sample_rate, **kwargs))\n",
    "    return np.log(mel_spectrogram + log_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34f65bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame(data, window_length, hop_length):\n",
    "    num_samples = data.shape[0]\n",
    "    num_frames = 1 + int(np.floor((num_samples - window_length) / hop_length))\n",
    "    shape = (num_frames, window_length) + data.shape[1:]\n",
    "    strides = (data.strides[0] * hop_length,) + data.strides\n",
    "    return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fa22bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_magnitude(signal, fft_length,\n",
    "                   hop_length=None,\n",
    "                   window_length=None):\n",
    "    frames = frame(signal, window_length, hop_length)\n",
    "    # Apply frame window to each frame. We use a periodic Hann (cosine of period\n",
    "    # window_length) instead of the symmetric Hann of np.hanning (period\n",
    "    # window_length-1).\n",
    "    window = periodic_hann(window_length)\n",
    "    windowed_frames = frames * window\n",
    "    return np.abs(np.fft.rfft(windowed_frames, int(fft_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1847431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_hann(window_length):\n",
    "    return 0.5 - (0.5 * np.cos(2 * np.pi / window_length *\n",
    "                               np.arange(window_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53662552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_to_mel_matrix(num_mel_bins=20,\n",
    "                              num_spectrogram_bins=129,\n",
    "                              audio_sample_rate=8000,\n",
    "                              lower_edge_hertz=125.0,\n",
    "                              upper_edge_hertz=3800.0):\n",
    "    nyquist_hertz = audio_sample_rate / 2.\n",
    "    if lower_edge_hertz < 0.0:\n",
    "        raise ValueError(\"lower_edge_hertz %.1f must be >= 0\" %\n",
    "                         lower_edge_hertz)\n",
    "    if lower_edge_hertz >= upper_edge_hertz:\n",
    "        raise ValueError(\"lower_edge_hertz %.1f >= upper_edge_hertz %.1f\" %\n",
    "                         (lower_edge_hertz, upper_edge_hertz))\n",
    "    if upper_edge_hertz > nyquist_hertz:\n",
    "        raise ValueError(\"upper_edge_hertz %.1f is greater than Nyquist %.1f\" %\n",
    "                         (upper_edge_hertz, nyquist_hertz))\n",
    "    spectrogram_bins_hertz = np.linspace(\n",
    "        0.0, nyquist_hertz, num_spectrogram_bins)\n",
    "    spectrogram_bins_mel = hertz_to_mel(spectrogram_bins_hertz)\n",
    "    # The i'th mel band (starting from i=1) has center frequency\n",
    "    # band_edges_mel[i], lower edge band_edges_mel[i-1], and higher edge\n",
    "    # band_edges_mel[i+1].  Thus, we need num_mel_bins + 2 values in\n",
    "    # the band_edges_mel arrays.\n",
    "    band_edges_mel = np.linspace(hertz_to_mel(lower_edge_hertz),\n",
    "                                 hertz_to_mel(upper_edge_hertz), num_mel_bins + 2)\n",
    "    # Matrix to post-multiply feature arrays whose rows are num_spectrogram_bins\n",
    "    # of spectrogram values.\n",
    "    mel_weights_matrix = np.empty((num_spectrogram_bins, num_mel_bins))\n",
    "    for i in range(num_mel_bins):\n",
    "        lower_edge_mel, center_mel, upper_edge_mel = band_edges_mel[i:i + 3]\n",
    "        # Calculate lower and upper slopes for every spectrogram bin.\n",
    "        # Line segments are linear in the *mel* domain, not hertz.\n",
    "        lower_slope = ((spectrogram_bins_mel - lower_edge_mel) /\n",
    "                       (center_mel - lower_edge_mel))\n",
    "        upper_slope = ((upper_edge_mel - spectrogram_bins_mel) /\n",
    "                       (upper_edge_mel - center_mel))\n",
    "        # .. then intersect them with each other and zero.\n",
    "        mel_weights_matrix[:, i] = np.maximum(0.0, np.minimum(lower_slope,\n",
    "                                                              upper_slope))\n",
    "    # HTK excludes the spectrogram DC bin; make sure it always gets a zero\n",
    "    # coefficient.\n",
    "    mel_weights_matrix[0, :] = 0.0\n",
    "    return mel_weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3df61f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hertz_to_mel(frequencies_hertz):\n",
    "    return 1127.0 * np.log(\n",
    "        1.0 + (frequencies_hertz / 700.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc0b6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures_VGGish(y, sr):\n",
    "    # Sound noise reduction\n",
    "    y = f_high_VGGish(y, sr)\n",
    "    \n",
    "    feat = waveform_to_examples(y, sr)\n",
    "        \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a025e0",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe3f66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a meta dataset\n",
    "def create_meta(yhat1, yhat2, yhat3):\n",
    "    # convert to dataframes\n",
    "    df_new1 = pd.DataFrame.from_dict(yhat1, orient='index', columns=['tr1', 'tr2', 'tr3', 'tr4', 'tr5',\n",
    "                                                                     'tr6', 'tr7', 'tr8', 'tr9', 'tr10',\n",
    "                                                                     'tr11', 'tr12', 'tr13', 'tr14', 'tr15',\n",
    "                                                                     'tr16', 'tr17', 'tr18', 'tr19', 'tr20',\n",
    "                                                                     'tr21'])\n",
    "    \n",
    "    df_new2 = pd.DataFrame.from_dict(yhat2, orient='index', columns=['en1', 'en2', 'en3', 'en4', 'en5',\n",
    "                                                                     'en6', 'en7', 'en8', 'en9', 'en10',\n",
    "                                                                     'en11', 'en12', 'en13', 'en14', 'en15',\n",
    "                                                                     'en16', 'en17', 'en18', 'en19', 'en20',\n",
    "                                                                     'en21'])\n",
    "    \n",
    "    df_new3 = pd.DataFrame.from_dict(yhat3, orient='index', columns=['vg1', 'vg2', 'vg3', 'vg4', 'vg5',\n",
    "                                                                     'vg6', 'vg7', 'vg8', 'vg9', 'vg10',\n",
    "                                                                     'vg11', 'vg12', 'vg13', 'vg14', 'vg15',\n",
    "                                                                     'vg16', 'vg17', 'vg18', 'vg19', 'vg20',\n",
    "                                                                     'vg21'])\n",
    "    # create a meta dataset\n",
    "    X = pd.concat([df_new1, df_new2, df_new3], axis=1, verify_integrity=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "143a5a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test soundscapes: 1\n"
     ]
    }
   ],
   "source": [
    "test_path = DATA_PATH + '/test_soundscapes/'\n",
    "files = [f.split('.')[0] for f in sorted(os.listdir(test_path))]\n",
    "print('Number of test soundscapes:', len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "700486a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del os\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80bb78fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_indexes [5, 11, 14, 18, 19]\n",
      "label_indexes [14, 19]\n",
      "label_indexes [1, 7, 13, 14, 16, 19]\n",
      "label_indexes [11, 13, 14, 19]\n",
      "label_indexes [7, 18, 19]\n",
      "label_indexes [1, 2, 7, 13, 16, 19]\n",
      "label_indexes [2, 7, 13, 14, 19]\n",
      "label_indexes [5, 7, 11, 14]\n",
      "label_indexes [2, 7, 13, 16, 19]\n",
      "label_indexes [5, 12, 14, 18, 19]\n",
      "label_indexes [2, 12, 14, 19]\n",
      "label_indexes [2, 7, 13, 14, 18, 19]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_453028782_akiapo_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_453028782_aniani_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_453028782_apapan_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soundscape_453028782_barpet_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>soundscape_453028782_crehon_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>soundscape_453028782_elepai_5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>soundscape_453028782_ercfra_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>soundscape_453028782_hawama_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>soundscape_453028782_hawcre_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>soundscape_453028782_hawgoo_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>soundscape_453028782_hawhaw_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>soundscape_453028782_hawpet1_5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>soundscape_453028782_houfin_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>soundscape_453028782_iiwi_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>soundscape_453028782_jabwar_5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>soundscape_453028782_maupar_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>soundscape_453028782_omao_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>soundscape_453028782_puaioh_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>soundscape_453028782_skylar_5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>soundscape_453028782_warwhe1_5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>soundscape_453028782_yefcan_5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            row_id  target\n",
       "0    soundscape_453028782_akiapo_5   False\n",
       "1    soundscape_453028782_aniani_5   False\n",
       "2    soundscape_453028782_apapan_5   False\n",
       "3    soundscape_453028782_barpet_5   False\n",
       "4    soundscape_453028782_crehon_5   False\n",
       "5    soundscape_453028782_elepai_5    True\n",
       "6    soundscape_453028782_ercfra_5   False\n",
       "7    soundscape_453028782_hawama_5   False\n",
       "8    soundscape_453028782_hawcre_5   False\n",
       "9    soundscape_453028782_hawgoo_5   False\n",
       "10   soundscape_453028782_hawhaw_5   False\n",
       "11  soundscape_453028782_hawpet1_5    True\n",
       "12   soundscape_453028782_houfin_5   False\n",
       "13     soundscape_453028782_iiwi_5   False\n",
       "14   soundscape_453028782_jabwar_5    True\n",
       "15   soundscape_453028782_maupar_5   False\n",
       "16     soundscape_453028782_omao_5   False\n",
       "17   soundscape_453028782_puaioh_5   False\n",
       "18   soundscape_453028782_skylar_5    True\n",
       "19  soundscape_453028782_warwhe1_5    True\n",
       "20   soundscape_453028782_yefcan_5   False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for f in files:\n",
    "    file_path = test_path + f + '.ogg'\n",
    "\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(file_path)\n",
    "    del file_path\n",
    "\n",
    "    # Get number of samples for 5 seconds\n",
    "    buffer = 5 * sr\n",
    "    block_min = 5 * sr\n",
    "\n",
    "    samples_total = len(audio)\n",
    "    samples_wrote = 0\n",
    "    counter = 1\n",
    "\n",
    "    while samples_wrote < samples_total:\n",
    "        # check if the buffer is not exceeding total samples\n",
    "        if buffer > (samples_total - samples_wrote):\n",
    "            buffer = samples_total - samples_wrote\n",
    "\n",
    "        block = audio[samples_wrote: (samples_wrote + buffer)]\n",
    "\n",
    "        # check if last block is as long as previous ones\n",
    "        if block.shape[0] < (block_min):\n",
    "            listofzeros = np.array([0] * (block_min - block.shape[0]))\n",
    "            block = np.hstack([block, listofzeros])\n",
    "\n",
    "        # Features extraction\n",
    "        trill_yhat = {}\n",
    "        block_trill = extractFeatures_trill(block, sr)\n",
    "        X = np.empty((1, 80000))\n",
    "        X[0] = np.array(block_trill)\n",
    "        tensor = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        pred_trill = Trill(tensor)\n",
    "        del block_trill\n",
    "        del X\n",
    "        #print('pred_trill', pred_trill)\n",
    "        trill_yhat[0] = pred_trill[0]\n",
    "        del pred_trill\n",
    "\n",
    "        gc.collect() \n",
    "        K.clear_session()\n",
    "\n",
    "        EfficientNetB0_yhat = {}\n",
    "        block_EfficientNetB0 = extractFeatures_EfficientNetB0(block, sr)\n",
    "        X = np.empty((1, conf.num_rows, conf.num_columns, conf.num_channels))\n",
    "        X[0] = np.array(block_EfficientNetB0)\n",
    "        tensor = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        pred_EfficientNetB0 = EfficientNetB0(tensor)\n",
    "        del block_EfficientNetB0\n",
    "        del X\n",
    "        #print('pred_EfficientNetB0', pred_EfficientNetB0)\n",
    "        EfficientNetB0_yhat[0] = pred_EfficientNetB0[0]\n",
    "        del pred_EfficientNetB0\n",
    "\n",
    "        gc.collect() \n",
    "        K.clear_session()\n",
    "\n",
    "        VGGish_yhat = {}\n",
    "        block_VGGish = extractFeatures_VGGish(block, sr)\n",
    "        X = np.empty((1, 5, 96, 64))\n",
    "        X[0] = np.array(block_VGGish)\n",
    "        X = X.reshape(1, 480, 64, 1)\n",
    "        tensor = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "        pred_VGGish = VGGish(tensor)\n",
    "        del block_VGGish\n",
    "        del X\n",
    "        #print('pred_VGGish', pred_VGGish)\n",
    "        VGGish_yhat[0] = pred_VGGish[0]\n",
    "        del pred_VGGish\n",
    "        del block\n",
    "\n",
    "        gc.collect() \n",
    "        K.clear_session()\n",
    "\n",
    "        # construct meta dataset\n",
    "        meta_X = create_meta(trill_yhat, EfficientNetB0_yhat, VGGish_yhat)\n",
    "        del trill_yhat, EfficientNetB0_yhat, VGGish_yhat\n",
    "        gc.collect()\n",
    "\n",
    "        # Prediction\n",
    "        pred_meta = meta_model.predict_proba(meta_X)\n",
    "        del meta_X\n",
    "        gc.collect()\n",
    "        #print('pred_meta', pred_meta)\n",
    "\n",
    "        index = 0\n",
    "        label_indexes = []\n",
    "        for score in pred_meta:\n",
    "            #print(index, score[0][1])\n",
    "            if score[0][1] >= 0.1:\n",
    "                label_indexes.append(index)\n",
    "            index += 1\n",
    "\n",
    "        print('label_indexes', label_indexes)\n",
    "\n",
    "        for b in scored_birds:\n",
    "            segment_end = counter * 5\n",
    "            row_id = f + '_' + b + '_' + str(segment_end)\n",
    "            target = False\n",
    "            for label_index in label_indexes:\n",
    "                if scored_birds[label_index] == b:\n",
    "                    target = True\n",
    "            data.append([row_id, target])\n",
    "\n",
    "        del label_indexes\n",
    "        gc.collect()\n",
    "\n",
    "        counter += 1\n",
    "        samples_wrote += buffer\n",
    "\n",
    "submission_df = pd.DataFrame(data, columns=['row_id', 'target'])\n",
    "submission_df.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55caca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(WORKING_PATH + 'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfc3f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp8",
   "language": "python",
   "name": "tfp8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "217px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

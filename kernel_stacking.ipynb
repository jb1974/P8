{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90bff9d0",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a428b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b857f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ce07718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Misc\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Data management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sound treatments\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "import resampy\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "\n",
    "# TRILL\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "assert tf.executing_eagerly()\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# EfficientNetB0\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# Meta model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Metrics\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.layers.netvlad import NetVLAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e8401",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69cc41a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Inactivate warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display Tensorlfow version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2854e768",
   "metadata": {},
   "source": [
    "!mkdir -p '/kaggle/working/blocks'\n",
    "!mkdir -p '/kaggle/working/blocks/features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53f27839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = '/kaggle/input/birdclef-2022/'\n",
    "#WORKING_PATH = '/kaggle/working/'\n",
    "#TRILL_PATH = '/kaggle/input/ziptrill/'\n",
    "#VGGISH_PATH = '/kaggle/input/vggishfull/'\n",
    "#MODEL_PATH = '/kaggle/input/models/'\n",
    "\n",
    "DATA_PATH = './data/'\n",
    "WORKING_PATH = './working/stacking/'\n",
    "TRILL_PATH = './working/stacking/trill/'\n",
    "VGGISH_PATH = './working/stacking/'\n",
    "MODEL_PATH = './working/stacking/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c47272b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_off = False\n",
    "e_off = False\n",
    "v_off = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0270101",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c081303",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akiapo',\n",
       " 'aniani',\n",
       " 'apapan',\n",
       " 'barpet',\n",
       " 'crehon',\n",
       " 'elepai',\n",
       " 'ercfra',\n",
       " 'hawama',\n",
       " 'hawcre',\n",
       " 'hawgoo',\n",
       " 'hawhaw',\n",
       " 'hawpet1',\n",
       " 'houfin',\n",
       " 'iiwi',\n",
       " 'jabwar',\n",
       " 'maupar',\n",
       " 'omao',\n",
       " 'puaioh',\n",
       " 'skylar',\n",
       " 'warwhe1',\n",
       " 'yefcan']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load meta data\n",
    "train_meta = pd.read_csv(DATA_PATH + 'train_metadata.csv')\n",
    "\n",
    "# Load scored birds\n",
    "with open(DATA_PATH + 'scored_birds.json') as sbfile:\n",
    "    scored_birds = json.load(sbfile)\n",
    "    \n",
    "# Focus on 21 scored classes\n",
    "labels = list(train_meta[train_meta['primary_label'].isin(scored_birds)]['primary_label'].unique())\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16bad5c",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4447ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(model_name):\n",
    "    if model_name == 'trill':\n",
    "        model = tf.keras.models.Sequential()\n",
    "        model.add(tf.keras.Input((80000,)))\n",
    "\n",
    "        trill_layer = hub.KerasLayer(\n",
    "            handle=TRILL_PATH,\n",
    "            trainable=False,\n",
    "            arguments={'sample_rate': int(16000)},\n",
    "            output_key='embedding',\n",
    "            output_shape=[None, 2048]\n",
    "        )\n",
    "\n",
    "        model.add(trill_layer)\n",
    "        model.add(NetVLAD(num_clusters=8))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dense(21, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(l=1e-5)))\n",
    "\n",
    "    elif model_name == 'efficientnetb0':\n",
    "        base_model = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), weights=None, pooling='avg')\n",
    "        dense = tf.keras.layers.Dense(142, activation='relu')(base_model.output)\n",
    "        outputs = tf.keras.layers.Dense(21, activation='sigmoid')(dense)\n",
    "        base_model.trainable = False\n",
    "        model = tf.keras.models.Model(inputs=base_model.input, outputs=outputs)\n",
    "        \n",
    "    elif model_name == 'vggish':\n",
    "        '''base_model, _, _ = vgk.get_embedding_model(hop_duration=0.25)   \n",
    "        dense = Dense(128, activation='relu')(base_model.output)\n",
    "        outputs = Dense(21, activation='sigmoid')(dense)      \n",
    "        base_model.trainable = False\n",
    "        model = Model(inputs=base_model.input, outputs=outputs)'''\n",
    "        \n",
    "        model = tf.keras.models.load_model(VGGISH_PATH + 'VGGish_full.h5')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e401a0",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c16283",
   "metadata": {},
   "source": [
    "## Feature extraxction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2854ae55",
   "metadata": {},
   "source": [
    "### Trill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c41bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sound noise reduction\n",
    "def f_high_trill(y, sr):\n",
    "    b, a = signal.butter(10, 1000/(sr/2), btype='highpass')\n",
    "    yf = signal.lfilter(b, a, y)\n",
    "    return yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b53d4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures_trill(y, sr):\n",
    "    # Sound noise reduction\n",
    "    y = f_high_trill(y, sr)\n",
    "    # Resample\n",
    "    y = librosa.resample(y, sr, 16000)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c65c8",
   "metadata": {},
   "source": [
    "### EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d04ef4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conf:\n",
    "    # Preprocessing settings\n",
    "    sampling_rate = 44100\n",
    "    n_mels = 224\n",
    "    hop_length = 494\n",
    "    n_fft = n_mels * 10\n",
    "    fmin = 20\n",
    "    fmax = 16000\n",
    "    \n",
    "    # Model parameters\n",
    "    num_rows = 224\n",
    "    num_columns = 224\n",
    "    num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00667336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_melspectrogram(audio):\n",
    "    spectrogram = librosa.feature.melspectrogram(audio,\n",
    "                                                 sr=conf.sampling_rate,\n",
    "                                                 n_mels=conf.n_mels,\n",
    "                                                 hop_length=conf.hop_length,\n",
    "                                                 n_fft=conf.n_fft,\n",
    "                                                 fmin=conf.fmin,\n",
    "                                                 fmax=conf.fmax)\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "314b178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    Converts a one channel array to a 3 channel one in [0, 255]\n",
    "    Arguments:\n",
    "        X {numpy array [H x W]} -- 2D array to convert\n",
    "    Keyword Arguments:\n",
    "        eps {float} -- To avoid dividing by 0 (default: {1e-6})\n",
    "        mean {None or np array} -- Mean for normalization (default: {None})\n",
    "        std {None or np array} -- Std for normalization (default: {None})\n",
    "    Returns:\n",
    "        numpy array [3 x H x W] -- RGB numpy array\n",
    "    \"\"\"\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    # Normalize to [0, 255]\n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53e469f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures_EfficientNetB0(y, sr):\n",
    "    # Extract features\n",
    "    feat = audio_to_melspectrogram(y)\n",
    "    feat = mono_to_color(feat)\n",
    "    feat = feat.astype(np.uint8)\n",
    "    \n",
    "    # EfficientNet preprocess\n",
    "    feat = preprocess_input(feat)\n",
    "    \n",
    "    X = np.empty((1, conf.num_rows, conf.num_columns, conf.num_channels))\n",
    "    x_features = feat.tolist()\n",
    "    X[0] = np.array(x_features)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffa8458",
   "metadata": {},
   "source": [
    "### VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5651795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sound noise reduction\n",
    "def f_high_VGGish(y,sr):\n",
    "    b,a = signal.butter(10, 2000/(sr/2), btype='highpass')\n",
    "    yf = signal.lfilter(b,a,y)\n",
    "    return yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46552579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveform_to_examples(data, sample_rate):\n",
    "    # Convert to mono.\n",
    "    if len(data.shape) > 1:\n",
    "        data = np.mean(data, axis=1)\n",
    "    # Resample to the rate assumed by VGGish.\n",
    "    if sample_rate != 16000:\n",
    "        data = resampy.resample(data, sample_rate, 16000)\n",
    "\n",
    "    # Compute log mel spectrogram features.\n",
    "    log_mel = log_mel_spectrogram(\n",
    "        data,\n",
    "        audio_sample_rate=16000,\n",
    "        log_offset=0.01,\n",
    "        window_length_secs=0.025,\n",
    "        hop_length_secs=0.010,\n",
    "        num_mel_bins=64,\n",
    "        lower_edge_hertz=125,\n",
    "        upper_edge_hertz=7500)\n",
    "\n",
    "    # Frame features into examples.\n",
    "    features_sample_rate = 1.0 / 0.010\n",
    "    example_window_length = int(round(0.96 * features_sample_rate))\n",
    "    example_hop_length = int(round(0.96 * features_sample_rate))\n",
    "    log_mel_examples = frame(\n",
    "        log_mel,\n",
    "        window_length=example_window_length,\n",
    "        hop_length=example_hop_length)\n",
    "    return log_mel_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14f70134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mel_spectrogram(data,\n",
    "                        audio_sample_rate=8000,\n",
    "                        log_offset=0.0,\n",
    "                        window_length_secs=0.025,\n",
    "                        hop_length_secs=0.010,\n",
    "                        **kwargs):\n",
    "    window_length_samples = int(round(audio_sample_rate * window_length_secs))\n",
    "    hop_length_samples = int(round(audio_sample_rate * hop_length_secs))\n",
    "    fft_length = 2 ** int(np.ceil(np.log(window_length_samples) / np.log(2.0)))\n",
    "    spectrogram = stft_magnitude(\n",
    "        data,\n",
    "        fft_length=fft_length,\n",
    "        hop_length=hop_length_samples,\n",
    "        window_length=window_length_samples)\n",
    "    mel_spectrogram = np.dot(spectrogram, spectrogram_to_mel_matrix(\n",
    "        num_spectrogram_bins=spectrogram.shape[1],\n",
    "        audio_sample_rate=audio_sample_rate, **kwargs))\n",
    "    return np.log(mel_spectrogram + log_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34f65bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame(data, window_length, hop_length):\n",
    "    num_samples = data.shape[0]\n",
    "    num_frames = 1 + int(np.floor((num_samples - window_length) / hop_length))\n",
    "    shape = (num_frames, window_length) + data.shape[1:]\n",
    "    strides = (data.strides[0] * hop_length,) + data.strides\n",
    "    return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fa22bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_magnitude(signal, fft_length,\n",
    "                   hop_length=None,\n",
    "                   window_length=None):\n",
    "    frames = frame(signal, window_length, hop_length)\n",
    "    # Apply frame window to each frame. We use a periodic Hann (cosine of period\n",
    "    # window_length) instead of the symmetric Hann of np.hanning (period\n",
    "    # window_length-1).\n",
    "    window = periodic_hann(window_length)\n",
    "    windowed_frames = frames * window\n",
    "    return np.abs(np.fft.rfft(windowed_frames, int(fft_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1847431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_hann(window_length):\n",
    "    return 0.5 - (0.5 * np.cos(2 * np.pi / window_length *\n",
    "                               np.arange(window_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53662552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_to_mel_matrix(num_mel_bins=20,\n",
    "                              num_spectrogram_bins=129,\n",
    "                              audio_sample_rate=8000,\n",
    "                              lower_edge_hertz=125.0,\n",
    "                              upper_edge_hertz=3800.0):\n",
    "    nyquist_hertz = audio_sample_rate / 2.\n",
    "    if lower_edge_hertz < 0.0:\n",
    "        raise ValueError(\"lower_edge_hertz %.1f must be >= 0\" %\n",
    "                         lower_edge_hertz)\n",
    "    if lower_edge_hertz >= upper_edge_hertz:\n",
    "        raise ValueError(\"lower_edge_hertz %.1f >= upper_edge_hertz %.1f\" %\n",
    "                         (lower_edge_hertz, upper_edge_hertz))\n",
    "    if upper_edge_hertz > nyquist_hertz:\n",
    "        raise ValueError(\"upper_edge_hertz %.1f is greater than Nyquist %.1f\" %\n",
    "                         (upper_edge_hertz, nyquist_hertz))\n",
    "    spectrogram_bins_hertz = np.linspace(\n",
    "        0.0, nyquist_hertz, num_spectrogram_bins)\n",
    "    spectrogram_bins_mel = hertz_to_mel(spectrogram_bins_hertz)\n",
    "    # The i'th mel band (starting from i=1) has center frequency\n",
    "    # band_edges_mel[i], lower edge band_edges_mel[i-1], and higher edge\n",
    "    # band_edges_mel[i+1].  Thus, we need num_mel_bins + 2 values in\n",
    "    # the band_edges_mel arrays.\n",
    "    band_edges_mel = np.linspace(hertz_to_mel(lower_edge_hertz),\n",
    "                                 hertz_to_mel(upper_edge_hertz), num_mel_bins + 2)\n",
    "    # Matrix to post-multiply feature arrays whose rows are num_spectrogram_bins\n",
    "    # of spectrogram values.\n",
    "    mel_weights_matrix = np.empty((num_spectrogram_bins, num_mel_bins))\n",
    "    for i in range(num_mel_bins):\n",
    "        lower_edge_mel, center_mel, upper_edge_mel = band_edges_mel[i:i + 3]\n",
    "        # Calculate lower and upper slopes for every spectrogram bin.\n",
    "        # Line segments are linear in the *mel* domain, not hertz.\n",
    "        lower_slope = ((spectrogram_bins_mel - lower_edge_mel) /\n",
    "                       (center_mel - lower_edge_mel))\n",
    "        upper_slope = ((upper_edge_mel - spectrogram_bins_mel) /\n",
    "                       (upper_edge_mel - center_mel))\n",
    "        # .. then intersect them with each other and zero.\n",
    "        mel_weights_matrix[:, i] = np.maximum(0.0, np.minimum(lower_slope,\n",
    "                                                              upper_slope))\n",
    "    # HTK excludes the spectrogram DC bin; make sure it always gets a zero\n",
    "    # coefficient.\n",
    "    mel_weights_matrix[0, :] = 0.0\n",
    "    return mel_weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3df61f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hertz_to_mel(frequencies_hertz):\n",
    "    return 1127.0 * np.log(\n",
    "        1.0 + (frequencies_hertz / 700.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc0b6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures_VGGish(y, sr):\n",
    "    # Sound noise reduction\n",
    "    y = f_high_VGGish(y, sr)\n",
    "    \n",
    "    feat = waveform_to_examples(y, sr)\n",
    "        \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a025e0",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "143a5a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test soundscapes: 1\n"
     ]
    }
   ],
   "source": [
    "test_path = DATA_PATH + '/test_soundscapes/'\n",
    "files = [f.split('.')[0] for f in sorted(os.listdir(test_path))]\n",
    "print('Number of test soundscapes:', len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13a3092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 374.57 MiB, increment: 0.12 MiB\n",
      "peak memory: 374.57 MiB, increment: 0.00 MiB\n",
      "peak memory: 374.57 MiB, increment: 0.00 MiB\n",
      "peak memory: 374.57 MiB, increment: 0.00 MiB\n",
      "peak memory: 399.96 MiB, increment: 0.00 MiB\n",
      "peak memory: 406.71 MiB, increment: 0.01 MiB\n",
      "peak memory: 407.48 MiB, increment: 0.00 MiB\n",
      "peak memory: 407.48 MiB, increment: 0.00 MiB\n",
      "peak memory: 409.25 MiB, increment: 0.03 MiB\n",
      "peak memory: 409.54 MiB, increment: 0.00 MiB\n",
      "peak memory: 409.29 MiB, increment: 0.00 MiB\n",
      "peak memory: 411.40 MiB, increment: 0.00 MiB\n",
      "peak memory: 411.66 MiB, increment: 0.00 MiB\n",
      "peak memory: 411.41 MiB, increment: 0.00 MiB\n",
      "peak memory: 413.59 MiB, increment: 0.00 MiB\n",
      "peak memory: 413.59 MiB, increment: 0.00 MiB\n",
      "peak memory: 413.44 MiB, increment: 0.00 MiB\n",
      "peak memory: 415.93 MiB, increment: 0.00 MiB\n",
      "peak memory: 415.86 MiB, increment: -0.06 MiB\n",
      "peak memory: 415.61 MiB, increment: 0.00 MiB\n",
      "peak memory: 417.87 MiB, increment: 0.00 MiB\n",
      "peak memory: 417.96 MiB, increment: 0.00 MiB\n",
      "peak memory: 417.71 MiB, increment: 0.00 MiB\n",
      "peak memory: 419.30 MiB, increment: 0.00 MiB\n",
      "peak memory: 419.67 MiB, increment: 0.00 MiB\n",
      "peak memory: 419.42 MiB, increment: 0.00 MiB\n",
      "peak memory: 421.82 MiB, increment: 0.00 MiB\n",
      "peak memory: 421.82 MiB, increment: 0.00 MiB\n",
      "peak memory: 421.57 MiB, increment: 0.00 MiB\n",
      "peak memory: 423.87 MiB, increment: 0.00 MiB\n",
      "peak memory: 423.87 MiB, increment: 0.00 MiB\n",
      "peak memory: 423.62 MiB, increment: 0.00 MiB\n",
      "peak memory: 426.86 MiB, increment: 0.00 MiB\n",
      "peak memory: 426.86 MiB, increment: 0.00 MiB\n",
      "peak memory: 426.71 MiB, increment: 0.00 MiB\n",
      "peak memory: 428.12 MiB, increment: 0.00 MiB\n",
      "peak memory: 428.12 MiB, increment: 0.00 MiB\n",
      "peak memory: 427.89 MiB, increment: 0.00 MiB\n",
      "peak memory: 430.12 MiB, increment: 0.00 MiB\n",
      "peak memory: 430.28 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit ids = []\n",
    "%memit dd_t = {}\n",
    "%memit dd_e = {}\n",
    "%memit dd_v = {}\n",
    "\n",
    "for f in files:\n",
    "    file_path = test_path + f + '.ogg'\n",
    "\n",
    "    # Load audio file\n",
    "    audio, sr = librosa.load(file_path)\n",
    "\n",
    "    # Get number of samples for 5 seconds\n",
    "    buffer = 5 * sr\n",
    "    block_min = 5 * sr\n",
    "\n",
    "    samples_total = len(audio)\n",
    "    samples_wrote = 0\n",
    "    counter = 1\n",
    "\n",
    "    while samples_wrote < samples_total:\n",
    "        # check if the buffer is not exceeding total samples\n",
    "        if buffer > (samples_total - samples_wrote):\n",
    "            buffer = samples_total - samples_wrote\n",
    "\n",
    "        # Block treatment\n",
    "        block = audio[samples_wrote: (samples_wrote + buffer)]\n",
    "        if block.shape[0] < (block_min):\n",
    "            listofzeros = np.array([0] * (block_min - block.shape[0]))\n",
    "            block = np.hstack([block, listofzeros])\n",
    "           \n",
    "        # row id\n",
    "        segment_end = counter * 5\n",
    "        row_id = f + '_bird_' + str(segment_end)\n",
    "        ids.append(row_id)\n",
    "\n",
    "        # Features extraction\n",
    "        if not t_off:\n",
    "            block_trill = extractFeatures_trill(block, sr)\n",
    "            %memit dd_t[row_id] = block_trill.reshape(1, -1)\n",
    "            #joblib.dump(block_trill.reshape(1, -1), WORKING_PATH + 'blocks/trill_' + row_id + '.jl')\n",
    "            \n",
    "        if not e_off:\n",
    "            block_EfficientNetB0 = extractFeatures_EfficientNetB0(block, sr)\n",
    "            %memit dd_e[row_id] = block_EfficientNetB0\n",
    "            #joblib.dump(block_EfficientNetB0, WORKING_PATH + 'blocks/EfficientNetB0_' + row_id + '.jl')\n",
    "        \n",
    "        if not v_off:\n",
    "            block_VGGish = extractFeatures_VGGish(block, sr)\n",
    "            %memit dd_v[row_id] = block_VGGish.reshape(1, 480, 64, 1)\n",
    "            #joblib.dump(block_VGGish.reshape(1, 480, 64, 1), WORKING_PATH + 'blocks/VGGish_' + row_id + '.jl')\n",
    "            \n",
    "        counter += 1\n",
    "        samples_wrote += buffer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e090584d",
   "metadata": {},
   "source": [
    "TEST 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ef9f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we will store our results\n",
    "pred = {'row_id': [], 'target': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48b50158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction for each chunk\n",
    "# Each scored bird gets a random value in our case\n",
    "# since we don't actually have a model\n",
    "for i in range(len(ids)):        \n",
    "    chunk_end_time = (i + 1) * 5\n",
    "    for bird in labels:\n",
    "\n",
    "        # This is our random prediction score for this bird\n",
    "        score = np.random.uniform()\n",
    "\n",
    "        # Assemble the row_id which we need to do for each scored bird\n",
    "        row_id = ids[i] + '_' + bird + '_' + str(chunk_end_time)\n",
    "\n",
    "        # Put the result into our prediction dict and\n",
    "        # apply a \"confidence\" threshold of 0.5\n",
    "        pred['row_id'].append(row_id)\n",
    "        pred['target'].append(True if score > 0.5 else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbc12094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   row_id  target\n",
      "0    soundscape_453028782_bird_5_akiapo_5    True\n",
      "1    soundscape_453028782_bird_5_aniani_5    True\n",
      "2    soundscape_453028782_bird_5_apapan_5    True\n",
      "3    soundscape_453028782_bird_5_barpet_5   False\n",
      "4    soundscape_453028782_bird_5_crehon_5    True\n",
      "5    soundscape_453028782_bird_5_elepai_5   False\n",
      "6    soundscape_453028782_bird_5_ercfra_5   False\n",
      "7    soundscape_453028782_bird_5_hawama_5   False\n",
      "8    soundscape_453028782_bird_5_hawcre_5   False\n",
      "9    soundscape_453028782_bird_5_hawgoo_5    True\n",
      "10   soundscape_453028782_bird_5_hawhaw_5    True\n",
      "11  soundscape_453028782_bird_5_hawpet1_5   False\n",
      "12   soundscape_453028782_bird_5_houfin_5   False\n",
      "13     soundscape_453028782_bird_5_iiwi_5   False\n",
      "14   soundscape_453028782_bird_5_jabwar_5    True\n",
      "15   soundscape_453028782_bird_5_maupar_5    True\n",
      "16     soundscape_453028782_bird_5_omao_5   False\n",
      "17   soundscape_453028782_bird_5_puaioh_5    True\n",
      "18   soundscape_453028782_bird_5_skylar_5    True\n",
      "19  soundscape_453028782_bird_5_warwhe1_5   False\n",
      "20   soundscape_453028782_bird_5_yefcan_5   False\n"
     ]
    }
   ],
   "source": [
    "# Make a new data frame and look at some results        \n",
    "results = pd.DataFrame(pred, columns = ['row_id', 'target'])\n",
    "\n",
    "# Quick sanity check\n",
    "print(results.head(21)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bef3fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our results to csv\n",
    "results.to_csv(WORKING_PATH + 'submission.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67988284",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d04c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e2409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07256512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16e78ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e6acd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7026bc51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batchsize = 12\n",
    "steps = len(ids) / batchsize\n",
    "calibration_limit = 0.1\n",
    "\n",
    "print('batchsize:', batchsize)\n",
    "print('steps:', steps)\n",
    "print('calibration_limit:', calibration_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207b6d0",
   "metadata": {},
   "source": [
    "### TRILL features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d441f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TRILL features\n",
    "m_Trill = create_cnn('trill')\n",
    "m_Trill.load_weights(MODEL_PATH + 'trill.h5')\n",
    "m_Trill.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=[tfa.metrics.F1Score(name='f1macro', num_classes=len(labels), average='macro')])\n",
    "\n",
    "count_prediction = 0\n",
    "\n",
    "for i in range(0, int(steps)+1):\n",
    "    temp = ids[i*batchsize:(i*batchsize)+batchsize]\n",
    "\n",
    "    X = np.empty((len(temp), 80000))\n",
    "    count_batch = 0\n",
    "    for batch in temp:\n",
    "        feat = joblib.load(WORKING_PATH + 'blocks/trill_' + batch + '.jl')\n",
    "        X[count_batch] = feat\n",
    "        count_batch += 1\n",
    "\n",
    "    # Prediction\n",
    "    if not t_off:\n",
    "        if X.shape[0] != 0:\n",
    "            pred_trill = m_Trill.predict(X)\n",
    "\n",
    "            for prediction in pred_trill:\n",
    "                count_prediction += 1\n",
    "                joblib.dump(prediction, WORKING_PATH +\n",
    "                            'blocks/features/trill_' + str(count_prediction) + '.jl')\n",
    "    else:\n",
    "        for j in range(0, count_batch):\n",
    "            count_prediction += 1\n",
    "            joblib.dump([1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                         0], WORKING_PATH +\n",
    "                        'blocks/features/trill_' + str(count_prediction) + '.jl')\n",
    "\n",
    "# Kill objects\n",
    "del temp\n",
    "del X\n",
    "del m_Trill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6759104e",
   "metadata": {},
   "source": [
    "### EfficientNetB0 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee5512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNetB0 features\n",
    "m_EfficientNetB0 = create_cnn('efficientnetb0')\n",
    "m_EfficientNetB0.load_weights(MODEL_PATH + 'EfficientNetB0.h5')\n",
    "m_EfficientNetB0.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                         loss='binary_crossentropy',\n",
    "                         metrics=[tfa.metrics.F1Score(name='f1macro', num_classes=len(labels), average='macro')])\n",
    "\n",
    "count_prediction = 0\n",
    "\n",
    "for i in range(0, int(steps)+1):\n",
    "    temp = ids[i*batchsize:(i*batchsize)+batchsize]\n",
    "\n",
    "    X = np.empty((len(temp), 224, 224, 3))\n",
    "    count_batch = 0\n",
    "    for batch in temp:\n",
    "        feat = joblib.load(\n",
    "            WORKING_PATH + 'blocks/EfficientNetB0_' + batch + '.jl')\n",
    "        X[count_batch] = feat\n",
    "        count_batch += 1\n",
    "\n",
    "    # Prediction\n",
    "    if not e_off:\n",
    "        if X.shape[0] != 0:\n",
    "            pred_EfficientNetB0 = m_EfficientNetB0.predict(X)\n",
    "\n",
    "            for prediction in pred_EfficientNetB0:\n",
    "                count_prediction += 1\n",
    "                joblib.dump(prediction, WORKING_PATH +\n",
    "                            'blocks/features/EfficientNetB0_' + str(count_prediction) + '.jl')\n",
    "    else:\n",
    "        for j in range(0, count_batch):\n",
    "            count_prediction += 1\n",
    "            joblib.dump([1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                         0], WORKING_PATH +\n",
    "                        'blocks/features/EfficientNetB0_' + str(count_prediction) + '.jl')\n",
    "\n",
    "# Kill objects\n",
    "del temp\n",
    "del X\n",
    "del m_EfficientNetB0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a621a2b9",
   "metadata": {},
   "source": [
    "### VGGish features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675d2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGGish features\n",
    "m_VGGish = create_cnn('vggish')\n",
    "m_VGGish.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=[tfa.metrics.F1Score(name='f1macro', num_classes=len(labels), average='macro')])\n",
    "\n",
    "count_prediction = 0\n",
    "\n",
    "for i in range(0, int(steps)+1):\n",
    "    temp = ids[i*batchsize:(i*batchsize)+batchsize]\n",
    "\n",
    "    X = np.empty((len(temp), 480, 64, 1))\n",
    "    count_batch = 0\n",
    "    for batch in temp:\n",
    "        feat = joblib.load(WORKING_PATH + 'blocks/VGGish_' + batch + '.jl')\n",
    "        X[count_batch] = feat\n",
    "        count_batch += 1\n",
    "\n",
    "    # Prediction\n",
    "    if not v_off:\n",
    "        if X.shape[0] != 0:\n",
    "            pred_VGGish = m_VGGish.predict(X)\n",
    "\n",
    "            for prediction in pred_VGGish:\n",
    "                count_prediction += 1\n",
    "                joblib.dump(prediction, WORKING_PATH +\n",
    "                            'blocks/features/VGGish_' + str(count_prediction) + '.jl')\n",
    "    else:\n",
    "        for j in range(0, count_batch):\n",
    "            count_prediction += 1\n",
    "            joblib.dump([1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                         0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "                         0], WORKING_PATH +\n",
    "                        'blocks/features/VGGish_' + str(count_prediction) + '.jl')\n",
    "\n",
    "# Kill objects\n",
    "del temp\n",
    "del X\n",
    "del m_VGGish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ede17d",
   "metadata": {},
   "source": [
    "### Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40278fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.empty((count_prediction, 63))\n",
    "\n",
    "for i in range(1, count_prediction+1):\n",
    "    # Prediction\n",
    "    pred_trill = joblib.load(\n",
    "        WORKING_PATH + 'blocks/features/trill_' + str(i) + '.jl')\n",
    "    pred_EfficientNetB0 = joblib.load(\n",
    "        WORKING_PATH + 'blocks/features/EfficientNetB0_' + str(i) + '.jl')\n",
    "    pred_VGGish = joblib.load(\n",
    "        WORKING_PATH + 'blocks/features/VGGish_' + str(i) + '.jl')\n",
    "\n",
    "    res_list = []\n",
    "    for j in pred_trill:\n",
    "        res_list.append(j)\n",
    "    for j in pred_EfficientNetB0:\n",
    "        res_list.append(j)\n",
    "    for j in pred_VGGish:\n",
    "        res_list.append(j)\n",
    "        \n",
    "    X[i-1] = np.array(res_list).reshape(1, -1)\n",
    "\n",
    "# construct meta dataset\n",
    "meta_X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fc852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "meta_model = joblib.load(MODEL_PATH + 'meta_model.jl')\n",
    "\n",
    "pred_meta = meta_model.predict_proba(meta_X)\n",
    "\n",
    "del meta_X\n",
    "del meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c763254",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for j in range(0, count_prediction):\n",
    "    label_indexes = []\n",
    "    for i in range(0, 21):\n",
    "        if pred_meta[i][j][1] >= calibration_limit:\n",
    "            label_indexes.append(i)\n",
    " \n",
    "    print('label_indexes', label_indexes)\n",
    "\n",
    "    for b in scored_birds:\n",
    "        row_id = ids[j].replace('bird', b)\n",
    "        target = False\n",
    "        for label_index in label_indexes:\n",
    "            if labels[label_index] == b:\n",
    "                target = True\n",
    "        data.append([row_id, target])\n",
    "\n",
    "submission_df = pd.DataFrame(data, columns=['row_id', 'target'])\n",
    "submission_df.head(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55caca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(WORKING_PATH + 'submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bf20a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp8",
   "language": "python",
   "name": "tfp8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

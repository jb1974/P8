{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90bff9d0",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bbdbdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce07718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Misc\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "# Data management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sound treatments\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Class weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# TRILL\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "assert tf.executing_eagerly()\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# EfficientNetB0\n",
    "from keras.applications.efficientnet import EfficientNetB0\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# VGGish\n",
    "from vggish import vggish_input\n",
    "from vggish import vggish_params as params\n",
    "import vggish_keras as vgk\n",
    "\n",
    "# Meta model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Metrics\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.layers.netvlad import NetVLAD\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e8401",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69cc41a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.6.0\n",
      "Default GPU Device: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Inactivate warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Allow to display all dataframes columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Display Tensorlfow version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print('No GPU found. Please ensure you have installed TensorFlow correctly')\n",
    "    \n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(\n",
    "        tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "    # Allow memory growth\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53f27839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA_PATH = '/kaggle/input/birdclef-2022/'\n",
    "#WORKING_PATH = '/kaggle/working/'\n",
    "#MODEL_PATH = '/kaggle/input/kernel-efficientnetb0-melspec/'\n",
    "\n",
    "DATA_PATH = './data/'\n",
    "WORKING_PATH = './working/stackingz/'\n",
    "MODEL_PATH = './working/stackingz/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4383306",
   "metadata": {},
   "source": [
    "# Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d85f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator_trill(Sequence):\n",
    "    def __init__(self,\n",
    "                 _X,\n",
    "                 batch_size=32,\n",
    "                 n_channels=1,\n",
    "                 n_columns=470,\n",
    "                 n_rows=120,\n",
    "                 shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.X = _X\n",
    "        self.n_channels = n_channels\n",
    "        self.n_columns = n_columns\n",
    "        self.n_rows = n_rows\n",
    "        self.shuffle = shuffle\n",
    "        self.img_indexes = np.arange(len(self.X))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.img_indexes) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temps = [self.img_indexes[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temps)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temps):\n",
    "        X = np.empty((self.batch_size, 80000))\n",
    "        y = np.empty((self.batch_size, 21), dtype=int)\n",
    "        for i, ID in enumerate(list_IDs_temps):\n",
    "            file_path = self.X.iloc[ID]['filename']\n",
    "\n",
    "            #audio, sr = librosa.load(file_path)\n",
    "            #feat = extractFeatures(audio, sr)\n",
    "\n",
    "            feat = data_mem[file_path]\n",
    "\n",
    "            x_features = feat.tolist()\n",
    "            label = self.X.iloc[ID]['target']\n",
    "            X[i] = np.array(x_features)\n",
    "            y[i] = mlb.transform([label])\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aad1abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator_EfficientNetB0(Sequence):\n",
    "    def __init__(self,\n",
    "                 _X,\n",
    "                 batch_size=32,\n",
    "                 n_channels=1,\n",
    "                 n_columns=470,\n",
    "                 n_rows=120,\n",
    "                 shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.X = _X\n",
    "        self.n_channels = n_channels\n",
    "        self.n_columns = n_columns\n",
    "        self.n_rows = n_rows\n",
    "        self.shuffle = shuffle\n",
    "        self.img_indexes = np.arange(len(self.X))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.img_indexes) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temps = [self.img_indexes[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temps)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temps):\n",
    "        X = np.empty((self.batch_size, self.n_rows, self.n_columns, self.n_channels))\n",
    "        y = np.empty((self.batch_size, len(mlb.classes_)), dtype=int)\n",
    "        for i, ID in enumerate(list_IDs_temps):\n",
    "            file_path = self.X.iloc[ID]['filename']\n",
    "            \n",
    "            #audio, sr = librosa.load(file_path)\n",
    "            #feat = extractFeatures(audio, sr)\n",
    "            \n",
    "            feat = data_mem[file_path]\n",
    "            \n",
    "            #x_features = feat.tolist()\n",
    "            label = self.X.iloc[ID]['target']\n",
    "            #X[i] = np.array(x_features)\n",
    "            X[i] = feat\n",
    "            y[i] = mlb.transform([label])\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caad47dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator_VGGish(Sequence):\n",
    "    def __init__(self,\n",
    "                 _X,\n",
    "                 batch_size=32,\n",
    "                 n_channels=1,\n",
    "                 n_columns=470,\n",
    "                 n_rows=120,\n",
    "                 shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.X = _X\n",
    "        self.n_channels = n_channels\n",
    "        self.n_columns = n_columns\n",
    "        self.n_rows = n_rows\n",
    "        self.shuffle = shuffle\n",
    "        self.img_indexes = np.arange(len(self.X))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.img_indexes) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # Find list of IDs\n",
    "        list_IDs_temps = [self.img_indexes[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temps)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temps):\n",
    "        X = np.empty((self.batch_size, self.n_rows, self.n_columns, self.n_channels))\n",
    "        y = np.empty((self.batch_size, len(mlb.classes_)), dtype=int)\n",
    "        for i, ID in enumerate(list_IDs_temps):\n",
    "            file_path = self.X.iloc[ID]['filename']\n",
    "            \n",
    "            #audio, sr = librosa.load(file_path)\n",
    "            #feat = extractFeatures(audio, sr)\n",
    "            \n",
    "            feat = data_mem[file_path]\n",
    "            \n",
    "            x_features = feat.tolist()\n",
    "            label = self.X.iloc[ID]['target']\n",
    "            X[i] = np.array(x_features)\n",
    "            y[i] = mlb.transform([label])\n",
    "        X = X.reshape(X.shape[0], self.n_rows, self.n_columns, self.n_channels)\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b2f262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mem = {}\n",
    "\n",
    "def LoadRAM():\n",
    "    # Load extracted features into RAM\n",
    "    data_mem.clear()\n",
    "\n",
    "    # Instantiate the progress bar\n",
    "    max_count = data_df.shape[0]\n",
    "    f = IntProgress(min=0, max=max_count)\n",
    "    # Display the progress bar\n",
    "    display(f)\n",
    "\n",
    "    temp = {}\n",
    "\n",
    "    for index, row in data_df.iterrows():\n",
    "        # Increment the progress bar\n",
    "        f.value += 1\n",
    "\n",
    "        # Get file path\n",
    "        file_path = row['filename']\n",
    "        # Load audio file\n",
    "        audio, sr = librosa.load(file_path)\n",
    "        # Extracxt features\n",
    "        feat = extractFeatures(audio, sr)\n",
    "        \n",
    "        # Store features into the dedicated dictionary\n",
    "        temp[row['filename']] = feat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0270101",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c081303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['akiapo',\n",
       " 'aniani',\n",
       " 'apapan',\n",
       " 'barpet',\n",
       " 'crehon',\n",
       " 'elepai',\n",
       " 'ercfra',\n",
       " 'hawama',\n",
       " 'hawcre',\n",
       " 'hawgoo',\n",
       " 'hawhaw',\n",
       " 'hawpet1',\n",
       " 'houfin',\n",
       " 'iiwi',\n",
       " 'jabwar',\n",
       " 'maupar',\n",
       " 'omao',\n",
       " 'puaioh',\n",
       " 'skylar',\n",
       " 'warwhe1',\n",
       " 'yefcan']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load meta data\n",
    "train_meta = pd.read_csv(DATA_PATH + 'train_metadata.csv')\n",
    "\n",
    "# Load scored birds\n",
    "with open(DATA_PATH + 'scored_birds.json') as sbfile:\n",
    "    scored_birds = json.load(sbfile)\n",
    "    \n",
    "# Focus on 21 scored classes\n",
    "labels = list(train_meta[train_meta['primary_label'].isin(scored_birds)]['primary_label'].unique())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fde482f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>original_filename</th>\n",
       "      <th>filename</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>akiapo</td>\n",
       "      <td>['apapan', 'hawama', 'iiwi']</td>\n",
       "      <td>akiapo/XC122399.ogg</td>\n",
       "      <td>./working/final/each5s/split_1_akiapo_XC122399...</td>\n",
       "      <td>(akiapo, apapan, hawama, iiwi)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akiapo</td>\n",
       "      <td>['apapan', 'hawama', 'iiwi']</td>\n",
       "      <td>akiapo/XC122399.ogg</td>\n",
       "      <td>./working/final/each5s/split_1_akiapo_XC122399...</td>\n",
       "      <td>(akiapo, apapan, hawama, iiwi)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>akiapo</td>\n",
       "      <td>['apapan', 'hawama', 'iiwi']</td>\n",
       "      <td>akiapo/XC122399.ogg</td>\n",
       "      <td>./working/final/each5s/split_1_akiapo_XC122399...</td>\n",
       "      <td>(akiapo, apapan, hawama, iiwi)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>akiapo</td>\n",
       "      <td>['apapan', 'hawama', 'iiwi']</td>\n",
       "      <td>akiapo/XC122399.ogg</td>\n",
       "      <td>./working/final/each5s/split_1_akiapo_XC122399...</td>\n",
       "      <td>(akiapo, apapan, hawama, iiwi)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>akiapo</td>\n",
       "      <td>['apapan', 'hawama', 'iiwi']</td>\n",
       "      <td>akiapo/XC122399.ogg</td>\n",
       "      <td>./working/final/each5s/split_2_akiapo_XC122399...</td>\n",
       "      <td>(akiapo, apapan, hawama, iiwi)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56315</th>\n",
       "      <td>yefcan</td>\n",
       "      <td>[]</td>\n",
       "      <td>yefcan/XC667142.ogg</td>\n",
       "      <td>./working/final/each5s/split_6_yefcan_XC667142...</td>\n",
       "      <td>(yefcan,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56316</th>\n",
       "      <td>yefcan</td>\n",
       "      <td>[]</td>\n",
       "      <td>yefcan/XC667142.ogg</td>\n",
       "      <td>./working/final/each5s/split_7_yefcan_XC667142...</td>\n",
       "      <td>(yefcan,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56317</th>\n",
       "      <td>yefcan</td>\n",
       "      <td>[]</td>\n",
       "      <td>yefcan/XC667142.ogg</td>\n",
       "      <td>./working/final/each5s/split_7_yefcan_XC667142...</td>\n",
       "      <td>(yefcan,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56318</th>\n",
       "      <td>yefcan</td>\n",
       "      <td>[]</td>\n",
       "      <td>yefcan/XC667142.ogg</td>\n",
       "      <td>./working/final/each5s/split_7_yefcan_XC667142...</td>\n",
       "      <td>(yefcan,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56319</th>\n",
       "      <td>yefcan</td>\n",
       "      <td>[]</td>\n",
       "      <td>yefcan/XC667142.ogg</td>\n",
       "      <td>./working/final/each5s/split_7_yefcan_XC667142...</td>\n",
       "      <td>(yefcan,)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56320 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      primary_label              secondary_labels    original_filename  \\\n",
       "0            akiapo  ['apapan', 'hawama', 'iiwi']  akiapo/XC122399.ogg   \n",
       "1            akiapo  ['apapan', 'hawama', 'iiwi']  akiapo/XC122399.ogg   \n",
       "2            akiapo  ['apapan', 'hawama', 'iiwi']  akiapo/XC122399.ogg   \n",
       "3            akiapo  ['apapan', 'hawama', 'iiwi']  akiapo/XC122399.ogg   \n",
       "4            akiapo  ['apapan', 'hawama', 'iiwi']  akiapo/XC122399.ogg   \n",
       "...             ...                           ...                  ...   \n",
       "56315        yefcan                            []  yefcan/XC667142.ogg   \n",
       "56316        yefcan                            []  yefcan/XC667142.ogg   \n",
       "56317        yefcan                            []  yefcan/XC667142.ogg   \n",
       "56318        yefcan                            []  yefcan/XC667142.ogg   \n",
       "56319        yefcan                            []  yefcan/XC667142.ogg   \n",
       "\n",
       "                                                filename  \\\n",
       "0      ./working/final/each5s/split_1_akiapo_XC122399...   \n",
       "1      ./working/final/each5s/split_1_akiapo_XC122399...   \n",
       "2      ./working/final/each5s/split_1_akiapo_XC122399...   \n",
       "3      ./working/final/each5s/split_1_akiapo_XC122399...   \n",
       "4      ./working/final/each5s/split_2_akiapo_XC122399...   \n",
       "...                                                  ...   \n",
       "56315  ./working/final/each5s/split_6_yefcan_XC667142...   \n",
       "56316  ./working/final/each5s/split_7_yefcan_XC667142...   \n",
       "56317  ./working/final/each5s/split_7_yefcan_XC667142...   \n",
       "56318  ./working/final/each5s/split_7_yefcan_XC667142...   \n",
       "56319  ./working/final/each5s/split_7_yefcan_XC667142...   \n",
       "\n",
       "                               target  \n",
       "0      (akiapo, apapan, hawama, iiwi)  \n",
       "1      (akiapo, apapan, hawama, iiwi)  \n",
       "2      (akiapo, apapan, hawama, iiwi)  \n",
       "3      (akiapo, apapan, hawama, iiwi)  \n",
       "4      (akiapo, apapan, hawama, iiwi)  \n",
       "...                               ...  \n",
       "56315                       (yefcan,)  \n",
       "56316                       (yefcan,)  \n",
       "56317                       (yefcan,)  \n",
       "56318                       (yefcan,)  \n",
       "56319                       (yefcan,)  \n",
       "\n",
       "[56320 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_pickle(WORKING_PATH + 'data_augmented_df.pkl')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2ebcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(data_df['target'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6944fb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['akiapo', 'aniani', 'apapan', 'barpet', 'crehon', 'elepai',\n",
       "       'ercfra', 'hawama', 'hawcre', 'hawgoo', 'hawhaw', 'hawpet1',\n",
       "       'houfin', 'iiwi', 'jabwar', 'maupar', 'omao', 'puaioh', 'skylar',\n",
       "       'warwhe1', 'yefcan'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4f659c",
   "metadata": {},
   "source": [
    "# Classes weight management function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a51b2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weight(generator, mu=0.15):\n",
    "    weights = {}\n",
    "\n",
    "    labels_dict = {}\n",
    "    count_class = 0\n",
    "    for item in mlb.classes_:\n",
    "        labels_dict[count_class] = 0\n",
    "\n",
    "        for index, row in generator.X.iterrows():\n",
    "            if item in row['target']:\n",
    "                labels_dict[count_class] += 1\n",
    "                \n",
    "        count_class += 1\n",
    "\n",
    "    total = sum(labels_dict.values())\n",
    "    keys = labels_dict.keys()\n",
    "\n",
    "    for i in sorted(keys):\n",
    "        score = np.log(mu*total/float(labels_dict[i]))\n",
    "        weights[i] = score if score > 1 else 1\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04729c09",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fada22a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "es_callback = EarlyStopping(monitor='val_loss',\n",
    "                            mode='min',\n",
    "                            patience=5,\n",
    "                            verbose=1,\n",
    "                            restore_best_weights=True\n",
    "                            )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.8,\n",
    "                              mode='min',\n",
    "                              patience=1,\n",
    "                              verbose=1,\n",
    "                              min_delta=0.0001,\n",
    "                              cooldown=1,\n",
    "                              min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a46a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train, X_valid, _, _ = train_test_split(\n",
    "    data_df, data_df['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00cf8e",
   "metadata": {},
   "source": [
    "## Trill-distilled/3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063c9590",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59fb2514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sound noise reduction\n",
    "def f_high(y,sr):\n",
    "    b,a = signal.butter(10, 1000/(sr/2), btype='highpass')\n",
    "    yf = signal.lfilter(b,a,y)\n",
    "    return yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3b43d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(y, sr):\n",
    "    # Sound noise reduction\n",
    "    y = f_high(y, sr)\n",
    "    # Resample\n",
    "    y = librosa.resample(y, sr, 16000, res_type='fft')\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "45c8d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    batch_size=32,\n",
    "    n_rows=224,\n",
    "    n_columns=216,\n",
    "    n_channels=3,\n",
    ")\n",
    "params_train = dict(\n",
    "    shuffle=False,\n",
    "    **params\n",
    ")\n",
    "params_valid = dict(\n",
    "    shuffle=False,\n",
    "    **params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c313a41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa9d581934847de96fd5a573993138c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=56320)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data in RAM to speed up training process\n",
    "data_mem = LoadRAM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e524eccf",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65633fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keras_model(num_classes, input_length, use_batchnorm=True, l2=1e-5,\n",
    "                    num_clusters=None, trainable=True, pooling='avg', hidden=0):\n",
    "    \"\"\"Make a model.\"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.Input((input_length,)))\n",
    "    \n",
    "    # 'https://tfhub.dev/google/nonsemantic-speech-benchmark/trill-distilled/3'\n",
    "    trill_layer = hub.KerasLayer(\n",
    "        handle=MODEL_PATH + 'trill/',\n",
    "        trainable=trainable,\n",
    "        arguments={'sample_rate': int(16000)},\n",
    "        output_key='embedding',\n",
    "        output_shape=[None, 2048]\n",
    "    )\n",
    "    \n",
    "    model.add(trill_layer)\n",
    "    \n",
    "    if num_clusters and num_clusters > 0:\n",
    "        model.add(NetVLAD(num_clusters=num_clusters))\n",
    "        if use_batchnorm:\n",
    "            model.add(tf.keras.layers.BatchNormalization())\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            # Average pooling\n",
    "            model.add(tf.keras.layers.GlobalAveragePooling1D())  \n",
    "        else:\n",
    "            model.add(tf.keras.layers.Lambda(lambda x: tf.reduce_mean(x, axis=1)))\n",
    "       \n",
    "    # Hidden layer\n",
    "    if hidden != 0:\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            hidden, \n",
    "            activation='relu'))\n",
    "    \n",
    "    # Fully connected\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        num_classes, \n",
    "        activation='sigmoid',\n",
    "        kernel_regularizer=tf.keras.regularizers.l2(l=l2)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f9258a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(num_clusters, use_batchnorm, pooling, hidden, fine_tune_at, model_path):\n",
    "    if fine_tune_at == None:\n",
    "        print('fine_tune_at == None')\n",
    "        model = get_keras_model(len(labels), \n",
    "                                80000, \n",
    "                                use_batchnorm=use_batchnorm, \n",
    "                                l2=1e-5,\n",
    "                                num_clusters=num_clusters, \n",
    "                                trainable=False,\n",
    "                                pooling=pooling,\n",
    "                                hidden=hidden\n",
    "                               )\n",
    "\n",
    "    else:\n",
    "        print('model.load_weights')\n",
    "        model = get_keras_model(len(labels), \n",
    "                                80000, \n",
    "                                use_batchnorm=use_batchnorm, \n",
    "                                l2=1e-5,\n",
    "                                num_clusters=num_clusters, \n",
    "                                trainable=True,\n",
    "                                pooling=pooling,\n",
    "                                hidden=hidden\n",
    "                               )\n",
    "\n",
    "        # Load existing weights\n",
    "        model.load_weights(model_path)\n",
    "\n",
    "    print('')\n",
    "    model.summary()\n",
    "    print('')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58345741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights...\n",
      "Create model...\n",
      "fine_tune_at == None\n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_3 (KerasLayer)   (None, None, 2048)        51964864  \n",
      "_________________________________________________________________\n",
      "net_vlad_2 (NetVLAD)         (None, 16384)             32776     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 21)                5397      \n",
      "=================================================================\n",
      "Total params: 56,263,133\n",
      "Trainable params: 4,265,501\n",
      "Non-trainable params: 51,997,632\n",
      "_________________________________________________________________\n",
      "\n",
      "fit...\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 287s 304ms/step - loss: 0.1722 - f1macro: 0.4229 - val_loss: 0.0611 - val_f1macro: 0.5887\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 264s 282ms/step - loss: 0.1006 - f1macro: 0.6125 - val_loss: 0.0460 - val_f1macro: 0.6286 ETA: 1:58 - loss: 0.1127 - f1macro - ETA: 1:57 - loss: 0.1126 - f1macro: 0.59 - ETA: 1:5 - ETA: 1:51 - loss: 0 - ETA: - - ETA: 36s - loss:  - ETA: 2 - ETA: 8s - loss: 0.1010 - f1macro: 0.\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 234s 250ms/step - loss: 0.0723 - f1macro: 0.6780 - val_loss: 0.0422 - val_f1macro: 0.65851: - ETA: 1:25 - loss - ETA: 1:22 - loss: 0.0721 - f1macro: 0.689 - ETA: 1:21 - loss: 0.0721 - f1macro: 0.68 - ETA: 1:21 - loss: 0.0719  - ETA: 1:18 - loss: 0.0719 -  - ETA: 1:16 - loss: 0.0713 - f1macro - ETA: 1:15 -  - ETA: 50s -  - ETA: 48s - loss: 0. - ETA: 10s - loss: 0.0 - ETA: 7s - loss: 0.0 - ETA: 3s - loss: 0.0724 - f1macro: 0. - ETA: 2s - loss: 0.0723 - f1macro: 0.6 - ETA: 2s - loss: 0.0723 - f\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 211s 225ms/step - loss: 0.0544 - f1macro: 0.7088 - val_loss: 0.0401 - val_f1macro: 0.6381\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 207s 221ms/step - loss: 0.0439 - f1macro: 0.6990 - val_loss: 0.0364 - val_f1macro: 0.6576\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 211s 224ms/step - loss: 0.0371 - f1macro: 0.7116 - val_loss: 0.0392 - val_f1macro: 0.6308\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 221s 236ms/step - loss: 0.0257 - f1macro: 0.7209 - val_loss: 0.0360 - val_f1macro: 0.6230\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 210s 224ms/step - loss: 0.0240 - f1macro: 0.7080 - val_loss: 0.0398 - val_f1macro: 0.6398\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 208s 221ms/step - loss: 0.0190 - f1macro: 0.7252 - val_loss: 0.0314 - val_f1macro: 0.6535\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 211s 225ms/step - loss: 0.0174 - f1macro: 0.7018 - val_loss: 0.0350 - val_f1macro: 0.6200\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 209s 223ms/step - loss: 0.0146 - f1macro: 0.6995 - val_loss: 0.0340 - val_f1macro: 0.6593\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 209s 222ms/step - loss: 0.0122 - f1macro: 0.7028 - val_loss: 0.0292 - val_f1macro: 0.6530\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 212s 226ms/step - loss: 0.0117 - f1macro: 0.7020 - val_loss: 0.0332 - val_f1macro: 0.62670\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 213s 227ms/step - loss: 0.0105 - f1macro: 0.6815 - val_loss: 0.0307 - val_f1macro: 0.6699\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 221s 235ms/step - loss: 0.0091 - f1macro: 0.6894 - val_loss: 0.0285 - val_f1macro: 0.6426\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 212s 226ms/step - loss: 0.0084 - f1macro: 0.6868 - val_loss: 0.0288 - val_f1macro: 0.6802\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 208s 222ms/step - loss: 0.0076 - f1macro: 0.6795 - val_loss: 0.0294 - val_f1macro: 0.6513\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 208s 222ms/step - loss: 0.0070 - f1macro: 0.6834 - val_loss: 0.0294 - val_f1macro: 0.6618\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 207s 221ms/step - loss: 0.0066 - f1macro: 0.6890 - val_loss: 0.0297 - val_f1macro: 0.6475\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 212s 226ms/step - loss: 0.0061 - f1macro: 0.6900 - val_loss: 0.0298 - val_f1macro: 0.6538\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "Epoch 00020: early stopping\n",
      "predict_on_batch...\n",
      "Class weights...\n",
      "Create model...\n",
      "fine_tune_at == None\n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_4 (KerasLayer)   (None, None, 2048)        51964864  \n",
      "_________________________________________________________________\n",
      "net_vlad_3 (NetVLAD)         (None, 16384)             32776     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 21)                5397      \n",
      "=================================================================\n",
      "Total params: 56,263,133\n",
      "Trainable params: 4,265,501\n",
      "Non-trainable params: 51,997,632\n",
      "_________________________________________________________________\n",
      "\n",
      "fit...\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 219s 231ms/step - loss: 0.1696 - f1macro: 0.4052 - val_loss: 0.0602 - val_f1macro: 0.5378\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 259s 275ms/step - loss: 0.0995 - f1macro: 0.5786 - val_loss: 0.0490 - val_f1macro: 0.5945 f1 - ETA: 3s - loss: 0.0997  - ETA: 1s - loss: 0.0997 - f1macro\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 236s 251ms/step - loss: 0.0703 - f1macro: 0.6687 - val_loss: 0.0460 - val_f1macro: 0.5905\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 221s 235ms/step - loss: 0.0534 - f1macro: 0.6697 - val_loss: 0.0451 - val_f1macro: 0.6026\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 218s 232ms/step - loss: 0.0414 - f1macro: 0.7075 - val_loss: 0.0400 - val_f1macro: 0.6735\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 214s 228ms/step - loss: 0.0354 - f1macro: 0.7019 - val_loss: 0.0359 - val_f1macro: 0.6760\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 213s 227ms/step - loss: 0.0291 - f1macro: 0.7191 - val_loss: 0.0351 - val_f1macro: 0.6671\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 216s 230ms/step - loss: 0.0266 - f1macro: 0.7098 - val_loss: 0.0411 - val_f1macro: 0.7156\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 210s 224ms/step - loss: 0.0218 - f1macro: 0.7479 - val_loss: 0.0351 - val_f1macro: 0.7160\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 212s 226ms/step - loss: 0.0161 - f1macro: 0.7544 - val_loss: 0.0304 - val_f1macro: 0.7405\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 228s 243ms/step - loss: 0.0149 - f1macro: 0.7486 - val_loss: 0.0319 - val_f1macro: 0.7119\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 214s 228ms/step - loss: 0.0125 - f1macro: 0.7521 - val_loss: 0.0325 - val_f1macro: 0.7401\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 228s 243ms/step - loss: 0.0109 - f1macro: 0.7389 - val_loss: 0.0292 - val_f1macro: 0.7242\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 221s 236ms/step - loss: 0.0105 - f1macro: 0.7443 - val_loss: 0.0306 - val_f1macro: 0.7209 - loss: 0.0106 - f1macro: 0.74 -\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 216s 230ms/step - loss: 0.0090 - f1macro: 0.7344 - val_loss: 0.0321 - val_f1macro: 0.6978\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 220s 235ms/step - loss: 0.0080 - f1macro: 0.7213 - val_loss: 0.0296 - val_f1macro: 0.6955\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 212s 226ms/step - loss: 0.0073 - f1macro: 0.7197 - val_loss: 0.0320 - val_f1macro: 0.7017\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 228s 243ms/step - loss: 0.0069 - f1macro: 0.7187 - val_loss: 0.0292 - val_f1macro: 0.6960\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 214s 229ms/step - loss: 0.0062 - f1macro: 0.7185 - val_loss: 0.0297 - val_f1macro: 0.6934\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "Epoch 20/50\n",
      "938/938 [==============================] - 214s 228ms/step - loss: 0.0057 - f1macro: 0.7147 - val_loss: 0.0304 - val_f1macro: 0.6915\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "Epoch 21/50\n",
      "938/938 [==============================] - 217s 231ms/step - loss: 0.0054 - f1macro: 0.7119 - val_loss: 0.0293 - val_f1macro: 0.6843\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "Epoch 22/50\n",
      "938/938 [==============================] - 216s 230ms/step - loss: 0.0051 - f1macro: 0.7085 - val_loss: 0.0294 - val_f1macro: 0.6907\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "Epoch 23/50\n",
      "938/938 [==============================] - 213s 227ms/step - loss: 0.0049 - f1macro: 0.7122 - val_loss: 0.0300 - val_f1macro: 0.6748\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "Epoch 00023: early stopping\n",
      "predict_on_batch...\n",
      "Class weights...\n",
      "Create model...\n",
      "fine_tune_at == None\n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_5 (KerasLayer)   (None, None, 2048)        51964864  \n",
      "_________________________________________________________________\n",
      "net_vlad_4 (NetVLAD)         (None, 16384)             32776     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 21)                5397      \n",
      "=================================================================\n",
      "Total params: 56,263,133\n",
      "Trainable params: 4,265,501\n",
      "Non-trainable params: 51,997,632\n",
      "_________________________________________________________________\n",
      "\n",
      "fit...\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 212s 223ms/step - loss: 0.1742 - f1macro: 0.4267 - val_loss: 0.0591 - val_f1macro: 0.5465\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 212s 226ms/step - loss: 0.1021 - f1macro: 0.5960 - val_loss: 0.0431 - val_f1macro: 0.6879\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 219s 233ms/step - loss: 0.0731 - f1macro: 0.6748 - val_loss: 0.0417 - val_f1macro: 0.6228\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 213s 227ms/step - loss: 0.0546 - f1macro: 0.7021 - val_loss: 0.0413 - val_f1macro: 0.6880\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 210s 224ms/step - loss: 0.0438 - f1macro: 0.6988 - val_loss: 0.0459 - val_f1macro: 0.6672\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 211s 225ms/step - loss: 0.0309 - f1macro: 0.7209 - val_loss: 0.0338 - val_f1macro: 0.6655\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 216s 230ms/step - loss: 0.0261 - f1macro: 0.7224 - val_loss: 0.0354 - val_f1macro: 0.7029\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 211s 225ms/step - loss: 0.0202 - f1macro: 0.7312 - val_loss: 0.0291 - val_f1macro: 0.7235\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 215s 229ms/step - loss: 0.0175 - f1macro: 0.7230 - val_loss: 0.0311 - val_f1macro: 0.6769\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 212s 226ms/step - loss: 0.0147 - f1macro: 0.7250 - val_loss: 0.0324 - val_f1macro: 0.7036\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 215s 229ms/step - loss: 0.0120 - f1macro: 0.7366 - val_loss: 0.0302 - val_f1macro: 0.6914\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 213s 227ms/step - loss: 0.0104 - f1macro: 0.7272 - val_loss: 0.0306 - val_f1macro: 0.6736\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 212s 226ms/step - loss: 0.0092 - f1macro: 0.7263 - val_loss: 0.0286 - val_f1macro: 0.7050\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 225s 240ms/step - loss: 0.0086 - f1macro: 0.7094 - val_loss: 0.0289 - val_f1macro: 0.6930\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 236s 252ms/step - loss: 0.0077 - f1macro: 0.7151 - val_loss: 0.0288 - val_f1macro: 0.6926ss: 0.0077 - f - ETA: 9s - loss: 0.0077 - f1macro: 0.71 - ETA: 8s - loss: 0.0077 - f1m\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 247s 263ms/step - loss: 0.0069 - f1macro: 0.7083 - val_loss: 0.0287 - val_f1macro: 0.68791:52 - loss: 0.0071 - ETA: 10s - loss: 0.0068 -  - ETA: 7s - loss: 0.0068 - f - ETA: 5s\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 246s 263ms/step - loss: 0.0063 - f1macro: 0.7031 - val_loss: 0.0296 - val_f1macro: 0.6739: 0.0063 - f1macro: \n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 217s 232ms/step - loss: 0.0059 - f1macro: 0.6962 - val_loss: 0.0291 - val_f1macro: 0.6722\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "Epoch 00018: early stopping\n",
      "predict_on_batch...\n"
     ]
    }
   ],
   "source": [
    "# collect out of sample predictions\n",
    "trill_yhat = {}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for train_ix, test_ix in kfold.split(X_train):\n",
    "    # get data\n",
    "    train_X, test_X = X_train.iloc[train_ix], X_train.iloc[test_ix]\n",
    "    \n",
    "    # Instanciate data generators\n",
    "    train_generator = DataGenerator_trill(train_X, **params_train)\n",
    "    test_generator = DataGenerator_trill(test_X, **params_train)\n",
    "    \n",
    "    # Class weights\n",
    "    print('Class weights...')\n",
    "    class_weights = class_weight(generator=train_generator, mu=0.675)\n",
    "    \n",
    "    # Create TRILL model\n",
    "    print('Create model...')\n",
    "    Trill = create_cnn(num_clusters=8, use_batchnorm=True,\n",
    "                       pooling=None, hidden=256,\n",
    "                       fine_tune_at=None, model_path=None)\n",
    "    Trill.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tfa.metrics.F1Score(name='f1macro', num_classes=len(labels), average='macro')])\n",
    "    \n",
    "    print('fit...')\n",
    "    Trill.fit(\n",
    "        train_generator,\n",
    "        validation_data=test_generator,\n",
    "        epochs=50,\n",
    "        callbacks=[es_callback, reduce_lr],\n",
    "        verbose=1,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Predict & store\n",
    "    print('predict_on_batch...')\n",
    "    for index, row in test_generator.X.iterrows():\n",
    "        pred = Trill.predict_on_batch(data_mem[row['filename']].reshape(1, -1))\n",
    "        trill_yhat[index] = pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9610855",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "126628ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Trill.save_weights(WORKING_PATH + 'trill.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "031ada7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./working/stackingz/trill_yhat.jl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(trill_yhat, WORKING_PATH + 'trill_yhat.jl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5a627",
   "metadata": {},
   "source": [
    "## EfficientNetB0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07027773",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "095eb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conf:\n",
    "    # Preprocessing settings\n",
    "    sampling_rate = 44100\n",
    "    n_mels = 224\n",
    "    hop_length = 494\n",
    "    n_fft = n_mels * 10\n",
    "    fmin = 20\n",
    "    fmax = 16000\n",
    "    \n",
    "    # Model parameters\n",
    "    num_rows = 224\n",
    "    num_columns = 224\n",
    "    num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a6306277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_melspectrogram(audio):\n",
    "    spectrogram = librosa.feature.melspectrogram(audio,\n",
    "                                                 sr=conf.sampling_rate,\n",
    "                                                 n_mels=conf.n_mels,\n",
    "                                                 hop_length=conf.hop_length,\n",
    "                                                 n_fft=conf.n_fft,\n",
    "                                                 fmin=conf.fmin,\n",
    "                                                 fmax=conf.fmax)\n",
    "    spectrogram = librosa.power_to_db(spectrogram)\n",
    "    spectrogram = spectrogram.astype(np.float32)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "88a00a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_to_color(X, eps=1e-6, mean=None, std=None):\n",
    "    \"\"\"\n",
    "    Converts a one channel array to a 3 channel one in [0, 255]\n",
    "    Arguments:\n",
    "        X {numpy array [H x W]} -- 2D array to convert\n",
    "    Keyword Arguments:\n",
    "        eps {float} -- To avoid dividing by 0 (default: {1e-6})\n",
    "        mean {None or np array} -- Mean for normalization (default: {None})\n",
    "        std {None or np array} -- Std for normalization (default: {None})\n",
    "    Returns:\n",
    "        numpy array [3 x H x W] -- RGB numpy array\n",
    "    \"\"\"\n",
    "    X = np.stack([X, X, X], axis=-1)\n",
    "\n",
    "    # Standardize\n",
    "    mean = mean or X.mean()\n",
    "    std = std or X.std()\n",
    "    X = (X - mean) / (std + eps)\n",
    "\n",
    "    # Normalize to [0, 255]\n",
    "    _min, _max = X.min(), X.max()\n",
    "\n",
    "    if (_max - _min) > eps:\n",
    "        V = np.clip(X, _min, _max)\n",
    "        V = 255 * (V - _min) / (_max - _min)\n",
    "        V = V.astype(np.uint8)\n",
    "    else:\n",
    "        V = np.zeros_like(X, dtype=np.uint8)\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d76890fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(y, sr):\n",
    "    # Extract features\n",
    "    feat = audio_to_melspectrogram(y)\n",
    "    feat = mono_to_color(feat)\n",
    "    feat = feat.astype(np.uint8)\n",
    "    \n",
    "    # EfficientNet preprocess\n",
    "    feat = preprocess_input(feat)\n",
    "    \n",
    "    X = np.empty((1, conf.num_rows, conf.num_columns, conf.num_channels))\n",
    "    x_features = feat.tolist()\n",
    "    X[0] = np.array(x_features)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aac05b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    batch_size=16,\n",
    "    n_rows=conf.num_rows,\n",
    "    n_columns=conf.num_columns,\n",
    "    n_channels=conf.num_channels,\n",
    ")\n",
    "params_train = dict(\n",
    "    shuffle=False,\n",
    "    **params\n",
    ")\n",
    "params_valid = dict(\n",
    "    shuffle=False,\n",
    "    **params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3f565fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202f46226d164e748d8bdf1093f9fec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=56320)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data in RAM to speed up training process\n",
    "data_mem.clear()\n",
    "data_mem = LoadRAM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d0a3f8",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ff71f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(fine_tune_at=None,\n",
    "               model_path=None\n",
    "               ):\n",
    "\n",
    "    # Instanciate model\n",
    "    from keras.applications.efficientnet import EfficientNetB0\n",
    "    base_model = EfficientNetB0(include_top=False, input_shape=(\n",
    "        conf.num_rows, conf.num_columns, conf.num_channels), weights='imagenet', pooling='avg')\n",
    "    # Hidden neurons' number (input + output neurons) * 2/3 - 21\n",
    "    dense = Dense(142, activation='relu')(\n",
    "        base_model.output)\n",
    "    outputs = Dense(len(mlb.classes_), activation='sigmoid')(dense)\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    if fine_tune_at == None:\n",
    "        model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "    else:\n",
    "        model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "        # Load existing weights\n",
    "        model.load_weights(model_path)\n",
    "\n",
    "        # Unfreeze model layers\n",
    "        model.trainable = True\n",
    "\n",
    "        # Freeze all the layers before the `fine_tune_at` layer\n",
    "        for layer in model.layers[:fine_tune_at]:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22d4f4dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights...\n",
      "Create model...\n",
      "fit...\n",
      "Epoch 1/50\n",
      "1877/1877 [==============================] - 225s 117ms/step - loss: 0.2373 - f1macro: 0.2479 - val_loss: 0.0930 - val_f1macro: 0.3042\n",
      "Epoch 2/50\n",
      "1877/1877 [==============================] - 236s 126ms/step - loss: 0.1861 - f1macro: 0.3610 - val_loss: 0.0817 - val_f1macro: 0.4327\n",
      "Epoch 3/50\n",
      "1877/1877 [==============================] - 281s 150ms/step - loss: 0.1681 - f1macro: 0.4258 - val_loss: 0.0781 - val_f1macro: 0.4110\n",
      "Epoch 4/50\n",
      "1877/1877 [==============================] - 283s 151ms/step - loss: 0.1559 - f1macro: 0.4595 - val_loss: 0.0786 - val_f1macro: 0.4701\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 5/50\n",
      "1877/1877 [==============================] - 278s 148ms/step - loss: 0.1458 - f1macro: 0.4820 - val_loss: 0.0679 - val_f1macro: 0.4766\n",
      "Epoch 6/50\n",
      "1877/1877 [==============================] - 288s 153ms/step - loss: 0.1378 - f1macro: 0.5007 - val_loss: 0.0685 - val_f1macro: 0.4712\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 7/50\n",
      "1877/1877 [==============================] - 298s 159ms/step - loss: 0.1295 - f1macro: 0.5339 - val_loss: 0.0646 - val_f1macro: 0.5147\n",
      "Epoch 8/50\n",
      "1877/1877 [==============================] - 298s 159ms/step - loss: 0.1252 - f1macro: 0.5352 - val_loss: 0.0639 - val_f1macro: 0.4839\n",
      "Epoch 9/50\n",
      "1877/1877 [==============================] - 283s 151ms/step - loss: 0.1205 - f1macro: 0.5456 - val_loss: 0.0619 - val_f1macro: 0.5064\n",
      "Epoch 10/50\n",
      "1877/1877 [==============================] - 275s 146ms/step - loss: 0.1177 - f1macro: 0.5651 - val_loss: 0.0646 - val_f1macro: 0.5228\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 11/50\n",
      "1877/1877 [==============================] - 269s 143ms/step - loss: 0.1119 - f1macro: 0.5724 - val_loss: 0.0601 - val_f1macro: 0.5099\n",
      "Epoch 12/50\n",
      "1877/1877 [==============================] - 256s 137ms/step - loss: 0.1091 - f1macro: 0.5870 - val_loss: 0.0576 - val_f1macro: 0.5410\n",
      "Epoch 13/50\n",
      "1877/1877 [==============================] - 266s 141ms/step - loss: 0.1072 - f1macro: 0.5878 - val_loss: 0.0599 - val_f1macro: 0.5360\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 14/50\n",
      "1877/1877 [==============================] - 260s 138ms/step - loss: 0.1030 - f1macro: 0.5963 - val_loss: 0.0556 - val_f1macro: 0.5362\n",
      "Epoch 15/50\n",
      "1877/1877 [==============================] - 243s 129ms/step - loss: 0.1011 - f1macro: 0.6101 - val_loss: 0.0565 - val_f1macro: 0.5415\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 16/50\n",
      "1877/1877 [==============================] - 229s 122ms/step - loss: 0.0981 - f1macro: 0.6085 - val_loss: 0.0564 - val_f1macro: 0.5370\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 17/50\n",
      "1877/1877 [==============================] - 232s 123ms/step - loss: 0.0949 - f1macro: 0.6030 - val_loss: 0.0552 - val_f1macro: 0.5560\n",
      "Epoch 18/50\n",
      "1877/1877 [==============================] - 275s 146ms/step - loss: 0.0928 - f1macro: 0.6268 - val_loss: 0.0558 - val_f1macro: 0.5273\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "Epoch 19/50\n",
      "1877/1877 [==============================] - 209s 111ms/step - loss: 0.0915 - f1macro: 0.6185 - val_loss: 0.0551 - val_f1macro: 0.5465\n",
      "Epoch 20/50\n",
      "1877/1877 [==============================] - 265s 141ms/step - loss: 0.0910 - f1macro: 0.6277 - val_loss: 0.0527 - val_f1macro: 0.5726\n",
      "Epoch 21/50\n",
      "1877/1877 [==============================] - 238s 127ms/step - loss: 0.0893 - f1macro: 0.6316 - val_loss: 0.0546 - val_f1macro: 0.5378\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "Epoch 22/50\n",
      "1877/1877 [==============================] - 204s 109ms/step - loss: 0.0883 - f1macro: 0.6431 - val_loss: 0.0534 - val_f1macro: 0.5597\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "Epoch 23/50\n",
      "1877/1877 [==============================] - 284s 151ms/step - loss: 0.0868 - f1macro: 0.6360 - val_loss: 0.0535 - val_f1macro: 0.5530\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "Epoch 24/50\n",
      "1877/1877 [==============================] - 228s 122ms/step - loss: 0.0856 - f1macro: 0.6403 - val_loss: 0.0533 - val_f1macro: 0.5633\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "Epoch 25/50\n",
      "1877/1877 [==============================] - 221s 118ms/step - loss: 0.0842 - f1macro: 0.6445 - val_loss: 0.0521 - val_f1macro: 0.5630s - los - ETA: 1s - loss:\n",
      "Epoch 26/50\n",
      "1877/1877 [==============================] - 205s 109ms/step - loss: 0.0843 - f1macro: 0.6435 - val_loss: 0.0524 - val_f1macro: 0.5544\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "Epoch 27/50\n",
      "1877/1877 [==============================] - 211s 112ms/step - loss: 0.0834 - f1macro: 0.6419 - val_loss: 0.0523 - val_f1macro: 0.5556\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "Epoch 28/50\n",
      "1877/1877 [==============================] - 219s 117ms/step - loss: 0.0826 - f1macro: 0.6497 - val_loss: 0.0528 - val_f1macro: 0.5626\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "Epoch 29/50\n",
      "1877/1877 [==============================] - 211s 112ms/step - loss: 0.0822 - f1macro: 0.6472 - val_loss: 0.0523 - val_f1macro: 0.5643\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "Epoch 30/50\n",
      "1877/1877 [==============================] - 213s 114ms/step - loss: 0.0816 - f1macro: 0.6475 - val_loss: 0.0525 - val_f1macro: 0.5631\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "Epoch 00030: early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8348d039ff542aba9e13608c2d3f5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=15019)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_on_batch...\n",
      "Class weights...\n",
      "Create model...\n",
      "fit...\n",
      "Epoch 1/50\n",
      "1877/1877 [==============================] - 209s 104ms/step - loss: 0.2330 - f1macro: 0.2565 - val_loss: 0.0993 - val_f1macro: 0.3210\n",
      "Epoch 2/50\n",
      "1877/1877 [==============================] - 204s 108ms/step - loss: 0.1842 - f1macro: 0.3700 - val_loss: 0.0830 - val_f1macro: 0.4304\n",
      "Epoch 3/50\n",
      "1877/1877 [==============================] - 229s 122ms/step - loss: 0.1658 - f1macro: 0.4136 - val_loss: 0.0790 - val_f1macro: 0.4085\n",
      "Epoch 4/50\n",
      "1877/1877 [==============================] - 208s 111ms/step - loss: 0.1540 - f1macro: 0.4645 - val_loss: 0.0803 - val_f1macro: 0.4589\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 5/50\n",
      "1877/1877 [==============================] - 218s 116ms/step - loss: 0.1415 - f1macro: 0.4960 - val_loss: 0.0731 - val_f1macro: 0.4679\n",
      "Epoch 6/50\n",
      "1877/1877 [==============================] - 224s 119ms/step - loss: 0.1356 - f1macro: 0.5075 - val_loss: 0.0664 - val_f1macro: 0.5047oss: 0.1357 -\n",
      "Epoch 7/50\n",
      "1877/1877 [==============================] - 218s 116ms/step - loss: 0.1288 - f1macro: 0.5272 - val_loss: 0.0652 - val_f1macro: 0.4952\n",
      "Epoch 8/50\n",
      "1877/1877 [==============================] - 188s 100ms/step - loss: 0.1241 - f1macro: 0.5362 - val_loss: 0.0680 - val_f1macro: 0.5195\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 9/50\n",
      "1877/1877 [==============================] - 224s 120ms/step - loss: 0.1163 - f1macro: 0.5563 - val_loss: 0.0619 - val_f1macro: 0.5105\n",
      "Epoch 10/50\n",
      "1877/1877 [==============================] - 202s 108ms/step - loss: 0.1136 - f1macro: 0.5694 - val_loss: 0.0611 - val_f1macro: 0.5355\n",
      "Epoch 11/50\n",
      "1877/1877 [==============================] - 214s 114ms/step - loss: 0.1105 - f1macro: 0.5641 - val_loss: 0.0663 - val_f1macro: 0.5128\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 12/50\n",
      "1877/1877 [==============================] - 208s 111ms/step - loss: 0.1050 - f1macro: 0.5974 - val_loss: 0.0586 - val_f1macro: 0.5355\n",
      "Epoch 13/50\n",
      "1877/1877 [==============================] - 209s 112ms/step - loss: 0.1018 - f1macro: 0.5867 - val_loss: 0.0587 - val_f1macro: 0.5602\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 14/50\n",
      "1877/1877 [==============================] - 207s 110ms/step - loss: 0.0983 - f1macro: 0.6104 - val_loss: 0.0600 - val_f1macro: 0.5356\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 15/50\n",
      "1877/1877 [==============================] - 205s 109ms/step - loss: 0.0942 - f1macro: 0.6056 - val_loss: 0.0559 - val_f1macro: 0.5530\n",
      "Epoch 16/50\n",
      "1877/1877 [==============================] - 217s 116ms/step - loss: 0.0921 - f1macro: 0.6133 - val_loss: 0.0556 - val_f1macro: 0.5644\n",
      "Epoch 17/50\n",
      "1877/1877 [==============================] - 207s 110ms/step - loss: 0.0917 - f1macro: 0.6204 - val_loss: 0.0564 - val_f1macro: 0.5772\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 18/50\n",
      "1877/1877 [==============================] - 204s 109ms/step - loss: 0.0885 - f1macro: 0.6259 - val_loss: 0.0547 - val_f1macro: 0.5690\n",
      "Epoch 19/50\n",
      "1877/1877 [==============================] - 194s 103ms/step - loss: 0.0870 - f1macro: 0.6240 - val_loss: 0.0545 - val_f1macro: 0.5569\n",
      "Epoch 20/50\n",
      "1877/1877 [==============================] - 206s 110ms/step - loss: 0.0868 - f1macro: 0.6248 - val_loss: 0.0550 - val_f1macro: 0.5642\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "Epoch 21/50\n",
      "1877/1877 [==============================] - 203s 108ms/step - loss: 0.0839 - f1macro: 0.6331 - val_loss: 0.0548 - val_f1macro: 0.5738\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "Epoch 22/50\n",
      "1877/1877 [==============================] - 215s 113ms/step - loss: 0.0824 - f1macro: 0.6405 - val_loss: 0.0546 - val_f1macro: 0.5709\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "Epoch 23/50\n",
      "1877/1877 [==============================] - 206s 110ms/step - loss: 0.0805 - f1macro: 0.6465 - val_loss: 0.0537 - val_f1macro: 0.5704\n",
      "Epoch 24/50\n",
      "1877/1877 [==============================] - 198s 106ms/step - loss: 0.0801 - f1macro: 0.6429 - val_loss: 0.0529 - val_f1macro: 0.5775\n",
      "Epoch 25/50\n",
      "1877/1877 [==============================] - 210s 112ms/step - loss: 0.0798 - f1macro: 0.6396 - val_loss: 0.0531 - val_f1macro: 0.5693\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "Epoch 26/50\n",
      "1877/1877 [==============================] - 211s 112ms/step - loss: 0.0787 - f1macro: 0.6452 - val_loss: 0.0525 - val_f1macro: 0.5856\n",
      "Epoch 27/50\n",
      "1877/1877 [==============================] - 201s 107ms/step - loss: 0.0781 - f1macro: 0.6436 - val_loss: 0.0529 - val_f1macro: 0.5663\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "Epoch 28/50\n",
      "1877/1877 [==============================] - 216s 115ms/step - loss: 0.0773 - f1macro: 0.6547 - val_loss: 0.0526 - val_f1macro: 0.5745\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "Epoch 29/50\n",
      "1877/1877 [==============================] - 214s 114ms/step - loss: 0.0767 - f1macro: 0.6519 - val_loss: 0.0526 - val_f1macro: 0.5738\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "Epoch 30/50\n",
      "1877/1877 [==============================] - 206s 110ms/step - loss: 0.0758 - f1macro: 0.6476 - val_loss: 0.0523 - val_f1macro: 0.5779\n",
      "Epoch 31/50\n",
      "1877/1877 [==============================] - 200s 107ms/step - loss: 0.0755 - f1macro: 0.6547 - val_loss: 0.0529 - val_f1macro: 0.5758\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "Epoch 32/50\n",
      "1877/1877 [==============================] - 211s 112ms/step - loss: 0.0756 - f1macro: 0.6590 - val_loss: 0.0521 - val_f1macro: 0.5847\n",
      "Epoch 33/50\n",
      "1877/1877 [==============================] - 205s 109ms/step - loss: 0.0749 - f1macro: 0.6612 - val_loss: 0.0523 - val_f1macro: 0.5807\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "Epoch 34/50\n",
      "1877/1877 [==============================] - 208s 111ms/step - loss: 0.0748 - f1macro: 0.6524 - val_loss: 0.0519 - val_f1macro: 0.5717\n",
      "Epoch 35/50\n",
      "1877/1877 [==============================] - 264s 141ms/step - loss: 0.0754 - f1macro: 0.6518 - val_loss: 0.0521 - val_f1macro: 0.5787\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "Epoch 36/50\n",
      "1877/1877 [==============================] - 252s 135ms/step - loss: 0.0751 - f1macro: 0.6574 - val_loss: 0.0522 - val_f1macro: 0.5806\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "Epoch 37/50\n",
      "1877/1877 [==============================] - 215s 114ms/step - loss: 0.0750 - f1macro: 0.6600 - val_loss: 0.0518 - val_f1macro: 0.5769\n",
      "Epoch 38/50\n",
      "1877/1877 [==============================] - 209s 111ms/step - loss: 0.0742 - f1macro: 0.6553 - val_loss: 0.0518 - val_f1macro: 0.5806\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "Epoch 39/50\n",
      "1877/1877 [==============================] - 214s 114ms/step - loss: 0.0734 - f1macro: 0.6588 - val_loss: 0.0518 - val_f1macro: 0.5801\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "Epoch 40/50\n",
      "1877/1877 [==============================] - 204s 109ms/step - loss: 0.0738 - f1macro: 0.6610 - val_loss: 0.0517 - val_f1macro: 0.5820 f\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "Epoch 41/50\n",
      "1877/1877 [==============================] - 217s 115ms/step - loss: 0.0734 - f1macro: 0.6502 - val_loss: 0.0517 - val_f1macro: 0.5790\n",
      "Epoch 42/50\n",
      "1877/1877 [==============================] - 209s 111ms/step - loss: 0.0735 - f1macro: 0.6642 - val_loss: 0.0518 - val_f1macro: 0.5857\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 43/50\n",
      "1877/1877 [==============================] - 203s 108ms/step - loss: 0.0730 - f1macro: 0.6559 - val_loss: 0.0518 - val_f1macro: 0.5807\n",
      "Epoch 44/50\n",
      "1877/1877 [==============================] - 207s 110ms/step - loss: 0.0737 - f1macro: 0.6650 - val_loss: 0.0517 - val_f1macro: 0.5795\n",
      "Epoch 45/50\n",
      "1877/1877 [==============================] - 213s 114ms/step - loss: 0.0731 - f1macro: 0.6541 - val_loss: 0.0514 - val_f1macro: 0.5815\n",
      "Epoch 46/50\n",
      "1877/1877 [==============================] - 205s 109ms/step - loss: 0.0734 - f1macro: 0.6629 - val_loss: 0.0519 - val_f1macro: 0.5795\n",
      "Epoch 47/50\n",
      "1877/1877 [==============================] - 201s 107ms/step - loss: 0.0738 - f1macro: 0.6609 - val_loss: 0.0518 - val_f1macro: 0.5804\n",
      "Epoch 48/50\n",
      "1877/1877 [==============================] - 211s 113ms/step - loss: 0.0734 - f1macro: 0.6684 - val_loss: 0.0518 - val_f1macro: 0.5788s: 0.0734 - f1macr - ET - ETA: 4s - loss: 0.0735 - - E\n",
      "Epoch 49/50\n",
      "1877/1877 [==============================] - 214s 114ms/step - loss: 0.0733 - f1macro: 0.6649 - val_loss: 0.0517 - val_f1macro: 0.5801\n",
      "Epoch 50/50\n",
      "1877/1877 [==============================] - 206s 110ms/step - loss: 0.0735 - f1macro: 0.6616 - val_loss: 0.0518 - val_f1macro: 0.5853\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd7a59b72e334bdb94ce06fd2631be7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=15019)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_on_batch...\n",
      "Class weights...\n",
      "Create model...\n",
      "fit...\n",
      "Epoch 1/50\n",
      "1877/1877 [==============================] - 200s 104ms/step - loss: 0.2375 - f1macro: 0.2476 - val_loss: 0.0871 - val_f1macro: 0.3616\n",
      "Epoch 2/50\n",
      "1877/1877 [==============================] - 216s 115ms/step - loss: 0.1847 - f1macro: 0.3856 - val_loss: 0.0820 - val_f1macro: 0.3841\n",
      "Epoch 3/50\n",
      "1877/1877 [==============================] - 203s 108ms/step - loss: 0.1662 - f1macro: 0.4391 - val_loss: 0.0745 - val_f1macro: 0.4729\n",
      "Epoch 4/50\n",
      "1877/1877 [==============================] - 206s 110ms/step - loss: 0.1531 - f1macro: 0.4732 - val_loss: 0.0715 - val_f1macro: 0.4797\n",
      "Epoch 5/50\n",
      "1877/1877 [==============================] - 211s 112ms/step - loss: 0.1434 - f1macro: 0.4902 - val_loss: 0.0700 - val_f1macro: 0.51571436 - f1macro: \n",
      "Epoch 6/50\n",
      "1877/1877 [==============================] - 215s 115ms/step - loss: 0.1358 - f1macro: 0.4958 - val_loss: 0.0674 - val_f1macro: 0.4774\n",
      "Epoch 7/50\n",
      "1877/1877 [==============================] - 212s 113ms/step - loss: 0.1295 - f1macro: 0.5060 - val_loss: 0.0654 - val_f1macro: 0.4985\n",
      "Epoch 8/50\n",
      "1877/1877 [==============================] - 203s 108ms/step - loss: 0.1241 - f1macro: 0.5275 - val_loss: 0.0624 - val_f1macro: 0.5147\n",
      "Epoch 9/50\n",
      "1877/1877 [==============================] - 209s 111ms/step - loss: 0.1198 - f1macro: 0.5354 - val_loss: 0.0612 - val_f1macro: 0.4657\n",
      "Epoch 10/50\n",
      "1877/1877 [==============================] - 199s 106ms/step - loss: 0.1151 - f1macro: 0.5516 - val_loss: 0.0621 - val_f1macro: 0.5159\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 11/50\n",
      "1877/1877 [==============================] - 203s 108ms/step - loss: 0.1079 - f1macro: 0.5690 - val_loss: 0.0586 - val_f1macro: 0.5457\n",
      "Epoch 12/50\n",
      "1877/1877 [==============================] - 203s 108ms/step - loss: 0.1049 - f1macro: 0.5647 - val_loss: 0.0572 - val_f1macro: 0.5413\n",
      "Epoch 13/50\n",
      "1877/1877 [==============================] - 212s 113ms/step - loss: 0.1030 - f1macro: 0.5829 - val_loss: 0.0570 - val_f1macro: 0.5407s: \n",
      "Epoch 14/50\n",
      "1877/1877 [==============================] - 201s 107ms/step - loss: 0.0982 - f1macro: 0.5867 - val_loss: 0.0579 - val_f1macro: 0.5403\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 15/50\n",
      "1877/1877 [==============================] - 199s 106ms/step - loss: 0.0938 - f1macro: 0.5972 - val_loss: 0.0553 - val_f1macro: 0.5566\n",
      "Epoch 16/50\n",
      "1877/1877 [==============================] - 206s 110ms/step - loss: 0.0916 - f1macro: 0.5948 - val_loss: 0.0539 - val_f1macro: 0.5702\n",
      "Epoch 17/50\n",
      "1877/1877 [==============================] - 214s 114ms/step - loss: 0.0897 - f1macro: 0.6064 - val_loss: 0.0543 - val_f1macro: 0.5541\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 18/50\n",
      "1877/1877 [==============================] - 207s 110ms/step - loss: 0.0860 - f1macro: 0.6150 - val_loss: 0.0517 - val_f1macro: 0.5869\n",
      "Epoch 19/50\n",
      "1877/1877 [==============================] - 207s 110ms/step - loss: 0.0838 - f1macro: 0.6263 - val_loss: 0.0532 - val_f1macro: 0.5849\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 20/50\n",
      "1877/1877 [==============================] - 208s 111ms/step - loss: 0.0802 - f1macro: 0.6352 - val_loss: 0.0530 - val_f1macro: 0.5628\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 21/50\n",
      "1877/1877 [==============================] - 212s 113ms/step - loss: 0.0772 - f1macro: 0.6448 - val_loss: 0.0507 - val_f1macro: 0.5805\n",
      "Epoch 22/50\n",
      "1877/1877 [==============================] - 205s 109ms/step - loss: 0.0759 - f1macro: 0.6442 - val_loss: 0.0524 - val_f1macro: 0.5685\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 23/50\n",
      "1877/1877 [==============================] - 198s 105ms/step - loss: 0.0746 - f1macro: 0.6408 - val_loss: 0.0498 - val_f1macro: 0.5887\n",
      "Epoch 24/50\n",
      "1877/1877 [==============================] - 197s 105ms/step - loss: 0.0733 - f1macro: 0.6534 - val_loss: 0.0501 - val_f1macro: 0.5874\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "Epoch 25/50\n",
      "1877/1877 [==============================] - 200s 106ms/step - loss: 0.0711 - f1macro: 0.6599 - val_loss: 0.0494 - val_f1macro: 0.5840\n",
      "Epoch 26/50\n",
      "1877/1877 [==============================] - 205s 109ms/step - loss: 0.0705 - f1macro: 0.6508 - val_loss: 0.0493 - val_f1macro: 0.5973\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "Epoch 27/50\n",
      "1877/1877 [==============================] - 206s 110ms/step - loss: 0.0701 - f1macro: 0.6616 - val_loss: 0.0494 - val_f1macro: 0.5881\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00013421773910522462.\n",
      "Epoch 28/50\n",
      "1877/1877 [==============================] - 204s 109ms/step - loss: 0.0690 - f1macro: 0.6662 - val_loss: 0.0507 - val_f1macro: 0.5897\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00010737419361248613.\n",
      "Epoch 29/50\n",
      "1877/1877 [==============================] - 204s 108ms/step - loss: 0.0674 - f1macro: 0.6617 - val_loss: 0.0489 - val_f1macro: 0.5865\n",
      "Epoch 30/50\n",
      "1877/1877 [==============================] - 213s 113ms/step - loss: 0.0674 - f1macro: 0.6647 - val_loss: 0.0496 - val_f1macro: 0.5925\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 8.589935605414213e-05.\n",
      "Epoch 31/50\n",
      "1877/1877 [==============================] - 209s 111ms/step - loss: 0.0666 - f1macro: 0.6656 - val_loss: 0.0486 - val_f1macro: 0.5956\n",
      "Epoch 32/50\n",
      "1877/1877 [==============================] - 213s 113ms/step - loss: 0.0664 - f1macro: 0.6712 - val_loss: 0.0494 - val_f1macro: 0.5931\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 6.871948717162013e-05.\n",
      "Epoch 33/50\n",
      "1877/1877 [==============================] - 203s 108ms/step - loss: 0.0666 - f1macro: 0.6692 - val_loss: 0.0484 - val_f1macro: 0.5993\n",
      "Epoch 34/50\n",
      "1877/1877 [==============================] - 182s 97ms/step - loss: 0.0660 - f1macro: 0.6713 - val_loss: 0.0486 - val_f1macro: 0.5913\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 5.497558740898967e-05.\n",
      "Epoch 35/50\n",
      "1877/1877 [==============================] - 211s 112ms/step - loss: 0.0652 - f1macro: 0.6760 - val_loss: 0.0484 - val_f1macro: 0.5933\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 4.398046876303852e-05.\n",
      "Epoch 36/50\n",
      "1877/1877 [==============================] - 190s 101ms/step - loss: 0.0650 - f1macro: 0.6681 - val_loss: 0.0482 - val_f1macro: 0.5929\n",
      "Epoch 37/50\n",
      "1877/1877 [==============================] - 214s 114ms/step - loss: 0.0647 - f1macro: 0.6717 - val_loss: 0.0485 - val_f1macro: 0.5984\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 3.518437442835421e-05.\n",
      "Epoch 38/50\n",
      "1877/1877 [==============================] - 214s 114ms/step - loss: 0.0644 - f1macro: 0.6772 - val_loss: 0.0489 - val_f1macro: 0.5955\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.8147498960606756e-05.\n",
      "Epoch 39/50\n",
      "1877/1877 [==============================] - 199s 106ms/step - loss: 0.0641 - f1macro: 0.6818 - val_loss: 0.0485 - val_f1macro: 0.5976\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.25179988774471e-05.\n",
      "Epoch 40/50\n",
      "1877/1877 [==============================] - 203s 108ms/step - loss: 0.0636 - f1macro: 0.6723 - val_loss: 0.0481 - val_f1macro: 0.5955\n",
      "Epoch 41/50\n",
      "1877/1877 [==============================] - 209s 112ms/step - loss: 0.0640 - f1macro: 0.6709 - val_loss: 0.0486 - val_f1macro: 0.5938\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.8014399392995985e-05.\n",
      "Epoch 42/50\n",
      "1877/1877 [==============================] - 207s 110ms/step - loss: 0.0636 - f1macro: 0.6776 - val_loss: 0.0483 - val_f1macro: 0.5971\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 1.4411519805435093e-05.\n",
      "Epoch 43/50\n",
      "1877/1877 [==============================] - 211s 112ms/step - loss: 0.0637 - f1macro: 0.6725 - val_loss: 0.0481 - val_f1macro: 0.5960\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.1529216135386379e-05.\n",
      "Epoch 44/50\n",
      "1877/1877 [==============================] - 204s 109ms/step - loss: 0.0631 - f1macro: 0.6728 - val_loss: 0.0483 - val_f1macro: 0.5946\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 45/50\n",
      "1877/1877 [==============================] - 214s 114ms/step - loss: 0.0631 - f1macro: 0.6750 - val_loss: 0.0480 - val_f1macro: 0.5977\n",
      "Epoch 46/50\n",
      "1877/1877 [==============================] - 211s 112ms/step - loss: 0.0629 - f1macro: 0.6759 - val_loss: 0.0482 - val_f1macro: 0.5958\n",
      "Epoch 47/50\n",
      "1877/1877 [==============================] - 200s 107ms/step - loss: 0.0634 - f1macro: 0.6806 - val_loss: 0.0482 - val_f1macro: 0.5962\n",
      "Epoch 48/50\n",
      "1877/1877 [==============================] - 208s 111ms/step - loss: 0.0633 - f1macro: 0.6731 - val_loss: 0.0481 - val_f1macro: 0.5988\n",
      "Epoch 49/50\n",
      "1877/1877 [==============================] - 205s 109ms/step - loss: 0.0633 - f1macro: 0.6750 - val_loss: 0.0481 - val_f1macro: 0.5968s: 0.0633 - f1macro: 0.675\n",
      "Epoch 50/50\n",
      "1877/1877 [==============================] - 203s 108ms/step - loss: 0.0629 - f1macro: 0.6811 - val_loss: 0.0480 - val_f1macro: 0.5994\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d768525f09a24ff58b6ba310b9fe64d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=15018)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_on_batch...\n"
     ]
    }
   ],
   "source": [
    "# collect out of sample predictions\n",
    "EfficientNetB0_yhat = {}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for train_ix, test_ix in kfold.split(X_train):\n",
    "    # get data\n",
    "    train_X, test_X = X_train.iloc[train_ix], X_train.iloc[test_ix]\n",
    "\n",
    "    # Instanciate data generators\n",
    "    train_generator = DataGenerator_EfficientNetB0(train_X, **params_train)\n",
    "    test_generator = DataGenerator_EfficientNetB0(test_X, **params_train)\n",
    "    \n",
    "    # Class weights\n",
    "    print('Class weights...')\n",
    "    class_weights = class_weight(generator=train_generator, mu=0.675)\n",
    "\n",
    "    # Create EfficientNetB0 model\n",
    "    print('Create model...')\n",
    "    EfficientNetB0 = create_cnn()\n",
    "    EfficientNetB0.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=[tfa.metrics.F1Score(name='f1macro', num_classes=len(labels), average='macro')])\n",
    "\n",
    "    print('fit...')\n",
    "    EfficientNetB0.fit(\n",
    "        train_generator,\n",
    "        validation_data=test_generator,\n",
    "        epochs=50,\n",
    "        callbacks=[es_callback, reduce_lr],\n",
    "        verbose=1,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Predict & store\n",
    "    # Instantiate the progress bar\n",
    "    max_count = test_generator.X.shape[0]\n",
    "    f = IntProgress(min=0, max=max_count)\n",
    "    # Display the progress bar\n",
    "    display(f)\n",
    "\n",
    "    print('predict_on_batch...')\n",
    "    for index, row in test_generator.X.iterrows():\n",
    "        # Increment the progress bar\n",
    "        f.value += 1\n",
    "        # Format data\n",
    "        X = np.empty((1, conf.num_rows, conf.num_columns, conf.num_channels))\n",
    "        X[0] = np.array(data_mem[row['filename']])\n",
    "        # Predict\n",
    "        pred = EfficientNetB0.predict_on_batch(X)\n",
    "        # Store prediction\n",
    "        EfficientNetB0_yhat[index] = pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871f3292",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbe21ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientNetB0.save_weights(WORKING_PATH + 'EfficientNetB0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3622edc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./working/stackingz/EfficientNetB0_yhat.jl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(EfficientNetB0_yhat, WORKING_PATH + 'EfficientNetB0_yhat.jl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49871563",
   "metadata": {},
   "source": [
    "## VGGish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3596d0",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b88ad064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sound noise reduction\n",
    "def f_high(y,sr):\n",
    "    b,a = signal.butter(10, 2000/(sr/2), btype='highpass')\n",
    "    yf = signal.lfilter(b,a,y)\n",
    "    return yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8d53bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waveform_to_examples(data, sample_rate):\n",
    "    # Convert to mono.\n",
    "    if len(data.shape) > 1:\n",
    "        data = np.mean(data, axis=1)\n",
    "    # Resample to the rate assumed by VGGish.\n",
    "    if sample_rate != 16000:\n",
    "        #data = resampy.resample(data, sample_rate, 16000)\n",
    "        data = librosa.resample(data, sample_rate, 16000, res_type='fft')\n",
    "\n",
    "    # Compute log mel spectrogram features.\n",
    "    log_mel = log_mel_spectrogram(\n",
    "        data,\n",
    "        audio_sample_rate=16000,\n",
    "        log_offset=0.01,\n",
    "        window_length_secs=0.025,\n",
    "        hop_length_secs=0.010,\n",
    "        num_mel_bins=64,\n",
    "        lower_edge_hertz=1500,\n",
    "        upper_edge_hertz=8000)\n",
    "\n",
    "    # Frame features into examples.\n",
    "    features_sample_rate = 1.0 / 0.010\n",
    "    example_window_length = int(round(0.96 * features_sample_rate))\n",
    "    example_hop_length = int(round(0.96 * features_sample_rate))\n",
    "    log_mel_examples = frame(\n",
    "        log_mel,\n",
    "        window_length=example_window_length,\n",
    "        hop_length=example_hop_length)\n",
    "    return log_mel_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1eec28ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mel_spectrogram(data,\n",
    "                        audio_sample_rate=8000,\n",
    "                        log_offset=0.0,\n",
    "                        window_length_secs=0.025,\n",
    "                        hop_length_secs=0.010,\n",
    "                        **kwargs):\n",
    "    window_length_samples = int(round(audio_sample_rate * window_length_secs))\n",
    "    hop_length_samples = int(round(audio_sample_rate * hop_length_secs))\n",
    "    fft_length = 2 ** int(np.ceil(np.log(window_length_samples) / np.log(2.0)))\n",
    "    spectrogram = stft_magnitude(\n",
    "        data,\n",
    "        fft_length=fft_length,\n",
    "        hop_length=hop_length_samples,\n",
    "        window_length=window_length_samples)\n",
    "    mel_spectrogram = np.dot(spectrogram, spectrogram_to_mel_matrix(\n",
    "        num_spectrogram_bins=spectrogram.shape[1],\n",
    "        audio_sample_rate=audio_sample_rate, **kwargs))\n",
    "    return np.log(mel_spectrogram + log_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab5f951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame(data, window_length, hop_length):\n",
    "    num_samples = data.shape[0]\n",
    "    num_frames = 1 + int(np.floor((num_samples - window_length) / hop_length))\n",
    "    shape = (num_frames, window_length) + data.shape[1:]\n",
    "    strides = (data.strides[0] * hop_length,) + data.strides\n",
    "    return np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "879f59d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_magnitude(signal, fft_length,\n",
    "                   hop_length=None,\n",
    "                   window_length=None):\n",
    "    frames = frame(signal, window_length, hop_length)\n",
    "    # Apply frame window to each frame. We use a periodic Hann (cosine of period\n",
    "    # window_length) instead of the symmetric Hann of np.hanning (period\n",
    "    # window_length-1).\n",
    "    window = periodic_hann(window_length)\n",
    "    windowed_frames = frames * window\n",
    "    return np.abs(np.fft.rfft(windowed_frames, int(fft_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ac49039",
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_hann(window_length):\n",
    "    return 0.5 - (0.5 * np.cos(2 * np.pi / window_length *\n",
    "                               np.arange(window_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "062792d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_to_mel_matrix(num_mel_bins=20,\n",
    "                              num_spectrogram_bins=129,\n",
    "                              audio_sample_rate=8000,\n",
    "                              lower_edge_hertz=125.0,\n",
    "                              upper_edge_hertz=3800.0):\n",
    "    nyquist_hertz = audio_sample_rate / 2.\n",
    "    if lower_edge_hertz < 0.0:\n",
    "        raise ValueError(\"lower_edge_hertz %.1f must be >= 0\" %\n",
    "                         lower_edge_hertz)\n",
    "    if lower_edge_hertz >= upper_edge_hertz:\n",
    "        raise ValueError(\"lower_edge_hertz %.1f >= upper_edge_hertz %.1f\" %\n",
    "                         (lower_edge_hertz, upper_edge_hertz))\n",
    "    if upper_edge_hertz > nyquist_hertz:\n",
    "        raise ValueError(\"upper_edge_hertz %.1f is greater than Nyquist %.1f\" %\n",
    "                         (upper_edge_hertz, nyquist_hertz))\n",
    "    spectrogram_bins_hertz = np.linspace(\n",
    "        0.0, nyquist_hertz, num_spectrogram_bins)\n",
    "    spectrogram_bins_mel = hertz_to_mel(spectrogram_bins_hertz)\n",
    "    # The i'th mel band (starting from i=1) has center frequency\n",
    "    # band_edges_mel[i], lower edge band_edges_mel[i-1], and higher edge\n",
    "    # band_edges_mel[i+1].  Thus, we need num_mel_bins + 2 values in\n",
    "    # the band_edges_mel arrays.\n",
    "    band_edges_mel = np.linspace(hertz_to_mel(lower_edge_hertz),\n",
    "                                 hertz_to_mel(upper_edge_hertz), num_mel_bins + 2)\n",
    "    # Matrix to post-multiply feature arrays whose rows are num_spectrogram_bins\n",
    "    # of spectrogram values.\n",
    "    mel_weights_matrix = np.empty((num_spectrogram_bins, num_mel_bins))\n",
    "    for i in range(num_mel_bins):\n",
    "        lower_edge_mel, center_mel, upper_edge_mel = band_edges_mel[i:i + 3]\n",
    "        # Calculate lower and upper slopes for every spectrogram bin.\n",
    "        # Line segments are linear in the *mel* domain, not hertz.\n",
    "        lower_slope = ((spectrogram_bins_mel - lower_edge_mel) /\n",
    "                       (center_mel - lower_edge_mel))\n",
    "        upper_slope = ((upper_edge_mel - spectrogram_bins_mel) /\n",
    "                       (upper_edge_mel - center_mel))\n",
    "        # .. then intersect them with each other and zero.\n",
    "        mel_weights_matrix[:, i] = np.maximum(0.0, np.minimum(lower_slope,\n",
    "                                                              upper_slope))\n",
    "    # HTK excludes the spectrogram DC bin; make sure it always gets a zero\n",
    "    # coefficient.\n",
    "    mel_weights_matrix[0, :] = 0.0\n",
    "    return mel_weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "176f8bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hertz_to_mel(frequencies_hertz):\n",
    "    return 1127.0 * np.log(\n",
    "        1.0 + (frequencies_hertz / 700.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ad35f433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(y, sr):\n",
    "    # Sound noise reduction\n",
    "    y = f_high(y, sr)\n",
    "    \n",
    "    feat = waveform_to_examples(y, sr)\n",
    "        \n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e09345cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    batch_size=32,\n",
    "    n_rows=5,\n",
    "    n_columns=96,\n",
    "    n_channels=64,\n",
    ")\n",
    "params_train = dict(\n",
    "    shuffle=True,\n",
    "    **params\n",
    ")\n",
    "params_valid = dict(\n",
    "    shuffle=False,\n",
    "    **params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0596f656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4908e092da894d36bd7011442b15f143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=56320)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data in RAM to speed up training process\n",
    "data_mem.clear()\n",
    "data_mem = LoadRAM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f1762",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e137df09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(fine_tune_at=None,\n",
    "               model_path=None\n",
    "               ):\n",
    "\n",
    "    # Instanciate model\n",
    "    base_model, _, _ = vgk.get_embedding_model(hop_duration=0.25)   \n",
    "    dense = Dense(128, activation='relu')(base_model.output)\n",
    "    outputs = Dense(len(mlb.classes_), activation='sigmoid')(dense)\n",
    "      \n",
    "    base_model.trainable = True\n",
    "    \n",
    "    if fine_tune_at == None:     \n",
    "        model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "    else:\n",
    "        model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "        # Load existing weights\n",
    "        model.load_weights(model_path)\n",
    "\n",
    "        # Unfreeze model layers\n",
    "        model.trainable = True\n",
    "\n",
    "        # Freeze all the layers before the `fine_tune_at` layer\n",
    "        for layer in model.layers[:fine_tune_at]:\n",
    "            layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f24558c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights...\n",
      "Create model...\n",
      "fit...\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 167s 174ms/step - loss: 0.3408 - f1macro: 0.0641 - val_loss: 0.1426 - val_f1macro: 0.1017cro: - ETA: 6s - loss: 0.3430 - f1macro:  - ETA: 1s - loss: 0.3410 - f1mac\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 145s 155ms/step - loss: 0.2743 - f1macro: 0.1453 - val_loss: 0.1314 - val_f1macro: 0.1629\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.2430 - f1macro: 0.1873 - val_loss: 0.1279 - val_f1macro: 0.1814\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.2208 - f1macro: 0.2403 - val_loss: 0.1113 - val_f1macro: 0.2354\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 142s 151ms/step - loss: 0.2012 - f1macro: 0.2932 - val_loss: 0.0968 - val_f1macro: 0.2830\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 141s 151ms/step - loss: 0.1851 - f1macro: 0.3366 - val_loss: 0.1054 - val_f1macro: 0.3503\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.1637 - f1macro: 0.3923 - val_loss: 0.0911 - val_f1macro: 0.3396\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.1497 - f1macro: 0.4098 - val_loss: 0.0872 - val_f1macro: 0.3980\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 141s 151ms/step - loss: 0.1359 - f1macro: 0.4803 - val_loss: 0.0876 - val_f1macro: 0.4380\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.1191 - f1macro: 0.5337 - val_loss: 0.0834 - val_f1macro: 0.4395\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 142s 151ms/step - loss: 0.1090 - f1macro: 0.5594 - val_loss: 0.0787 - val_f1macro: 0.4426\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 142s 151ms/step - loss: 0.1019 - f1macro: 0.5685 - val_loss: 0.0820 - val_f1macro: 0.4758\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 142s 152ms/step - loss: 0.0842 - f1macro: 0.6069 - val_loss: 0.0864 - val_f1macro: 0.5023\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.0728 - f1macro: 0.6331 - val_loss: 0.0827 - val_f1macro: 0.5174\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.0623 - f1macro: 0.6578 - val_loss: 0.0907 - val_f1macro: 0.4975\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.0534 - f1macro: 0.6675 - val_loss: 0.0970 - val_f1macro: 0.5099\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "Epoch 00016: early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a22f46d99b430da8346001d3fcde31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=15019)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_on_batch...\n",
      "Class weights...\n",
      "Create model...\n",
      "fit...\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 139s 148ms/step - loss: 0.3427 - f1macro: 0.0532 - val_loss: 0.1544 - val_f1macro: 0.0671\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 138s 147ms/step - loss: 0.2744 - f1macro: 0.1462 - val_loss: 0.1292 - val_f1macro: 0.1523\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 139s 148ms/step - loss: 0.2381 - f1macro: 0.1841 - val_loss: 0.1222 - val_f1macro: 0.2074\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 138s 148ms/step - loss: 0.2159 - f1macro: 0.2505 - val_loss: 0.1041 - val_f1macro: 0.2753\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 141s 151ms/step - loss: 0.1959 - f1macro: 0.3088 - val_loss: 0.1037 - val_f1macro: 0.2969\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 142s 152ms/step - loss: 0.1790 - f1macro: 0.3345 - val_loss: 0.0946 - val_f1macro: 0.3329\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 141s 151ms/step - loss: 0.1644 - f1macro: 0.3895 - val_loss: 0.0907 - val_f1macro: 0.3713\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.1518 - f1macro: 0.4107 - val_loss: 0.0875 - val_f1macro: 0.3831\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 142s 151ms/step - loss: 0.1405 - f1macro: 0.4388 - val_loss: 0.0888 - val_f1macro: 0.3900\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 141s 151ms/step - loss: 0.1206 - f1macro: 0.4882 - val_loss: 0.0794 - val_f1macro: 0.4281\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 142s 151ms/step - loss: 0.1082 - f1macro: 0.5257 - val_loss: 0.0808 - val_f1macro: 0.4596\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.0941 - f1macro: 0.5853 - val_loss: 0.0773 - val_f1macro: 0.4788\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 143s 153ms/step - loss: 0.0826 - f1macro: 0.6074 - val_loss: 0.0817 - val_f1macro: 0.5092\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 142s 152ms/step - loss: 0.0727 - f1macro: 0.6324 - val_loss: 0.0878 - val_f1macro: 0.5127\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.0598 - f1macro: 0.6691 - val_loss: 0.0886 - val_f1macro: 0.5277\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.0505 - f1macro: 0.6924 - val_loss: 0.0909 - val_f1macro: 0.5486\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.0435 - f1macro: 0.7022 - val_loss: 0.1043 - val_f1macro: 0.5486\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ed0f6d36eb4d0983dd9c0a38aa9f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=15019)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_on_batch...\n",
      "Class weights...\n",
      "Create model...\n",
      "fit...\n",
      "Epoch 1/50\n",
      "938/938 [==============================] - 139s 148ms/step - loss: 0.3456 - f1macro: 0.0609 - val_loss: 0.1612 - val_f1macro: 0.0659\n",
      "Epoch 2/50\n",
      "938/938 [==============================] - 138s 147ms/step - loss: 0.2824 - f1macro: 0.1445 - val_loss: 0.1262 - val_f1macro: 0.1773\n",
      "Epoch 3/50\n",
      "938/938 [==============================] - 138s 147ms/step - loss: 0.2433 - f1macro: 0.2028 - val_loss: 0.1090 - val_f1macro: 0.2057\n",
      "Epoch 4/50\n",
      "938/938 [==============================] - 140s 149ms/step - loss: 0.2184 - f1macro: 0.2423 - val_loss: 0.1035 - val_f1macro: 0.2397\n",
      "Epoch 5/50\n",
      "938/938 [==============================] - 139s 149ms/step - loss: 0.1985 - f1macro: 0.2958 - val_loss: 0.0951 - val_f1macro: 0.2879\n",
      "Epoch 6/50\n",
      "938/938 [==============================] - 140s 149ms/step - loss: 0.1804 - f1macro: 0.3305 - val_loss: 0.0882 - val_f1macro: 0.3322\n",
      "Epoch 7/50\n",
      "938/938 [==============================] - 140s 149ms/step - loss: 0.1667 - f1macro: 0.3802 - val_loss: 0.0886 - val_f1macro: 0.3356\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 8/50\n",
      "938/938 [==============================] - 139s 148ms/step - loss: 0.1448 - f1macro: 0.4361 - val_loss: 0.0815 - val_f1macro: 0.3851\n",
      "Epoch 9/50\n",
      "938/938 [==============================] - 139s 148ms/step - loss: 0.1309 - f1macro: 0.4814 - val_loss: 0.0810 - val_f1macro: 0.4170\n",
      "Epoch 10/50\n",
      "938/938 [==============================] - 140s 149ms/step - loss: 0.1191 - f1macro: 0.5157 - val_loss: 0.0780 - val_f1macro: 0.4536\n",
      "Epoch 11/50\n",
      "938/938 [==============================] - 140s 149ms/step - loss: 0.1092 - f1macro: 0.5592 - val_loss: 0.0732 - val_f1macro: 0.4645\n",
      "Epoch 12/50\n",
      "938/938 [==============================] - 141s 150ms/step - loss: 0.1017 - f1macro: 0.5538 - val_loss: 0.0758 - val_f1macro: 0.4598\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "Epoch 13/50\n",
      "938/938 [==============================] - 140s 149ms/step - loss: 0.0855 - f1macro: 0.5860 - val_loss: 0.0771 - val_f1macro: 0.4626\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "Epoch 14/50\n",
      "938/938 [==============================] - 140s 149ms/step - loss: 0.0734 - f1macro: 0.6139 - val_loss: 0.0715 - val_f1macro: 0.4889\n",
      "Epoch 15/50\n",
      "938/938 [==============================] - 140s 149ms/step - loss: 0.0654 - f1macro: 0.6382 - val_loss: 0.0791 - val_f1macro: 0.5328\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.\n",
      "Epoch 16/50\n",
      "938/938 [==============================] - 139s 148ms/step - loss: 0.0574 - f1macro: 0.6653 - val_loss: 0.0788 - val_f1macro: 0.5526\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00032768002711236477.\n",
      "Epoch 17/50\n",
      "938/938 [==============================] - 139s 149ms/step - loss: 0.0467 - f1macro: 0.6987 - val_loss: 0.0870 - val_f1macro: 0.5571\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0002621440216898918.\n",
      "Epoch 18/50\n",
      "938/938 [==============================] - 140s 149ms/step - loss: 0.0406 - f1macro: 0.7067 - val_loss: 0.0927 - val_f1macro: 0.5601\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00020971521735191345.\n",
      "Epoch 19/50\n",
      "938/938 [==============================] - 139s 148ms/step - loss: 0.0345 - f1macro: 0.7330 - val_loss: 0.1002 - val_f1macro: 0.5789f1macr\n",
      "Restoring model weights from the end of the best epoch.\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00016777217388153076.\n",
      "Epoch 00019: early stopping\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3592206e214bf7bd8fa7b62b4de98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=15018)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_on_batch...\n"
     ]
    }
   ],
   "source": [
    "# collect out of sample predictions\n",
    "VGGish_yhat = {}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for train_ix, test_ix in kfold.split(X_train):\n",
    "    # get data\n",
    "    train_X, test_X = X_train.iloc[train_ix], X_train.iloc[test_ix]\n",
    "\n",
    "    # Instanciate data generators\n",
    "    train_generator = DataGenerator_VGGish(train_X, **params_train)\n",
    "    test_generator = DataGenerator_VGGish(test_X, **params_train)\n",
    "\n",
    "    # Class weights\n",
    "    print('Class weights...')\n",
    "    class_weights = class_weight(generator=train_generator, mu=0.675)\n",
    "\n",
    "    # Create VGGish model\n",
    "    print('Create model...')\n",
    "    VGGish = create_cnn()\n",
    "    VGGish.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=[tfa.metrics.F1Score(name='f1macro', num_classes=len(labels), average='macro')])\n",
    "\n",
    "    print('fit...')\n",
    "    VGGish.fit(\n",
    "        train_generator,\n",
    "        validation_data=test_generator,\n",
    "        epochs=50,\n",
    "        callbacks=[es_callback, reduce_lr],\n",
    "        verbose=1,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    # Predict & store\n",
    "    # Instantiate the progress bar\n",
    "    max_count = test_generator.X.shape[0]\n",
    "    f = IntProgress(min=0, max=max_count)\n",
    "    # Display the progress bar\n",
    "    display(f)\n",
    "\n",
    "    print('predict_on_batch...')\n",
    "    for index, row in test_generator.X.iterrows():\n",
    "        # Increment the progress bar\n",
    "        f.value += 1\n",
    "        # Format data\n",
    "        X = np.empty((1, 5, 96, 64))\n",
    "        X[0] = np.array(data_mem[row['filename']])\n",
    "        X = X.reshape(1, 480, 64, 1)\n",
    "        # Predict\n",
    "        pred = VGGish.predict_on_batch(X)\n",
    "        # Store prediction\n",
    "        VGGish_yhat[index] = pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c12d5d",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cb6d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGGish.save_weights(WORKING_PATH + 'VGGish.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1bdfa04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./working/stackingz/VGGish_yhat.jl']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(VGGish_yhat, WORKING_PATH + 'VGGish_yhat.jl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017e5187",
   "metadata": {},
   "source": [
    "## Meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a25f337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a meta dataset\n",
    "def create_meta_dataset(data_x, yhat1, yhat2, yhat3):\n",
    "    # convert to dataframes\n",
    "    df_new1 = pd.DataFrame.from_dict(yhat1, orient='index', columns=['tr1', 'tr2', 'tr3', 'tr4', 'tr5',\n",
    "                                                                     'tr6', 'tr7', 'tr8', 'tr9', 'tr10',\n",
    "                                                                     'tr11', 'tr12', 'tr13', 'tr14', 'tr15',\n",
    "                                                                     'tr16', 'tr17', 'tr18', 'tr19', 'tr20',\n",
    "                                                                     'tr21'])\n",
    "    \n",
    "    df_new2 = pd.DataFrame.from_dict(yhat2, orient='index', columns=['en1', 'en2', 'en3', 'en4', 'en5',\n",
    "                                                                     'en6', 'en7', 'en8', 'en9', 'en10',\n",
    "                                                                     'en11', 'en12', 'en13', 'en14', 'en15',\n",
    "                                                                     'en16', 'en17', 'en18', 'en19', 'en20',\n",
    "                                                                     'en21'])\n",
    "    \n",
    "    df_new3 = pd.DataFrame.from_dict(yhat3, orient='index', columns=['vg1', 'vg2', 'vg3', 'vg4', 'vg5',\n",
    "                                                                     'vg6', 'vg7', 'vg8', 'vg9', 'vg10',\n",
    "                                                                     'vg11', 'vg12', 'vg13', 'vg14', 'vg15',\n",
    "                                                                     'vg16', 'vg17', 'vg18', 'vg19', 'vg20',\n",
    "                                                                     'vg21'])\n",
    "    # create a meta dataset\n",
    "    X = pd.concat([data_x, df_new1, df_new2, df_new3], axis=1, verify_integrity=True)\n",
    "    y = mlb.transform(X['target'])\n",
    "\n",
    "    X = X.drop(['primary_label', 'secondary_labels',\n",
    "                'original_filename', 'filename', 'target'], axis=1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "76f69612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload yhats\n",
    "trill_yhat = joblib.load(WORKING_PATH + 'trill_yhat.jl')\n",
    "EfficientNetB0_yhat = joblib.load(WORKING_PATH + 'EfficientNetB0_yhat.jl')\n",
    "VGGish_yhat = joblib.load(WORKING_PATH + 'VGGish_yhat.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "930d34bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct meta dataset\n",
    "meta_X_train, meta_y_train = create_meta_dataset(X_train, trill_yhat, EfficientNetB0_yhat, VGGish_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39a7254e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct meta classifier\n",
    "meta_model = RandomForestClassifier()\n",
    "meta_model.fit(meta_X_train, meta_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "306b65d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./working/stackingz/meta_model.jl']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "joblib.dump(meta_model, WORKING_PATH + 'meta_model.jl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f381d",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd29028",
   "metadata": {},
   "source": [
    "### Sub models on hold out dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f9fa22f",
   "metadata": {},
   "source": [
    "Replay preprocessing + model for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a297c4",
   "metadata": {},
   "source": [
    "#### Trill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a500b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator_trill = DataGenerator_trill(X_valid, **params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "22f1c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine_tune_at == None\n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer_7 (KerasLayer)   (None, None, 2048)        51964864  \n",
      "_________________________________________________________________\n",
      "net_vlad_6 (NetVLAD)         (None, 16384)             32776     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 16384)             65536     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 21)                5397      \n",
      "=================================================================\n",
      "Total params: 56,263,133\n",
      "Trainable params: 4,265,501\n",
      "Non-trainable params: 51,997,632\n",
      "_________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Trill = create_cnn(num_clusters=8, use_batchnorm=True,\n",
    "                   pooling=None, hidden=256,\n",
    "                   fine_tune_at=None, model_path=None)\n",
    "Trill.load_weights(WORKING_PATH + 'trill.h5')\n",
    "Trill.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=[tfa.metrics.F1Score(name='f1macro', num_classes=len(labels), average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43aac2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.029031455516815186, 0.6876097321510315]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_trill = Trill.evaluate_generator(valid_generator_trill)\n",
    "pred_trill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "29b4bf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pred_trill = {}\n",
    "\n",
    "for index, row in valid_generator_trill.X.iterrows():\n",
    "    pred = Trill.predict_on_batch(data_mem[row['filename']].reshape(1, -1))\n",
    "    meta_pred_trill[index] = pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c12b4667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./working/stackingz/meta_pred_trill.jl']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(meta_pred_trill, WORKING_PATH + 'meta_pred_trill.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa8b8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del meta_pred_trill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57411fb",
   "metadata": {},
   "source": [
    "#### EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c70cac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator_EfficientNetB0 = DataGenerator_EfficientNetB0(X_valid, **params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "588a1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "EfficientNetB0 = create_cnn()\n",
    "EfficientNetB0.load_weights(WORKING_PATH + 'EfficientNetB0.h5')\n",
    "EfficientNetB0.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=[tfa.metrics.F1Score(name='f1macro', num_classes=len(labels), average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2f2c14f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04925493150949478, 0.6120861768722534]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_EfficientNetB0 = EfficientNetB0.evaluate_generator(valid_generator_EfficientNetB0)\n",
    "pred_EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5d9b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pred_EfficientNetB0 = {}\n",
    "\n",
    "for index, row in valid_generator_EfficientNetB0.X.iterrows():\n",
    "    # Format data\n",
    "    X = np.empty((1, conf.num_rows, conf.num_columns, conf.num_channels))\n",
    "    X[0] = np.array(data_mem[row['filename']])\n",
    "    # Predict\n",
    "    pred = EfficientNetB0.predict_on_batch(X)\n",
    "    # Store prediction\n",
    "    meta_pred_EfficientNetB0[index] = pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "71b8b9ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./working/stackingz/meta_pred_EfficientNetB0.jl']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(meta_pred_EfficientNetB0, WORKING_PATH + 'meta_pred_EfficientNetB0.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d4b57ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del meta_pred_EfficientNetB0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b10825",
   "metadata": {},
   "source": [
    "#### VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7230dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator_VGGish = DataGenerator_VGGish(X_valid, **params_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d51688fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGGish = create_cnn()\n",
    "VGGish.load_weights(WORKING_PATH + 'VGGish.h5')\n",
    "VGGish.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "               loss='binary_crossentropy',\n",
    "               metrics=[tfa.metrics.F1Score(name='f1macro', num_classes=len(labels), average='macro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "85695396",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.save_model(VGGish, WORKING_PATH + 'VGGish_full.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "29e8a859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07626143842935562, 0.48580777645111084]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_VGGish = VGGish.evaluate_generator(valid_generator_VGGish)\n",
    "pred_VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "73292221",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pred_VGGish = {}\n",
    "\n",
    "for index, row in valid_generator_VGGish.X.iterrows():\n",
    "    # Format data\n",
    "    X = np.empty((1, 5, 96, 64))\n",
    "    X[0] = np.array(data_mem[row['filename']])\n",
    "    X = X.reshape(1, 480, 64, 1)\n",
    "    # Predict\n",
    "    pred = VGGish.predict_on_batch(X)\n",
    "    # Store prediction\n",
    "    meta_pred_VGGish[index] = pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7e588b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./working/stackingz/meta_pred_VGGish.jl']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(meta_pred_VGGish, WORKING_PATH + 'meta_pred_VGGish.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cb75630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del meta_pred_VGGish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced932e",
   "metadata": {},
   "source": [
    "### Meta model on hold out dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b6211025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload meta_model\n",
    "meta_model = joblib.load(WORKING_PATH + 'meta_model.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "aa43268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_pred_trill = joblib.load(WORKING_PATH + 'meta_pred_trill.jl')\n",
    "meta_pred_EfficientNetB0 = joblib.load(WORKING_PATH + 'meta_pred_EfficientNetB0.jl')\n",
    "meta_pred_VGGish = joblib.load(WORKING_PATH + 'meta_pred_VGGish.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4bcabd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct meta dataset\n",
    "meta_X_valid, meta_y_valid = create_meta_dataset(X_valid, meta_pred_trill, meta_pred_EfficientNetB0, meta_pred_VGGish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4f4a4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_meta = meta_model.predict(meta_X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "646f0dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8984301251579543\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(meta_y_valid, pred_meta, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b41d13de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAFUCAYAAAApnTu7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhjklEQVR4nO3de7hVdb3v8feHBYo3vADeQAITUwTUBDVqI+bOWxl22amZoVt0s0/qabdNPdouL5mlbTNLI85O00w000N4Iw+ZIifdIog32CobMZdQCSZ4CZXF9/wxxsLpZK7FBNaYgzHH5/U862GO32/MMb5z6DM/c/zGTRGBmZmVV7e8CzAzs3w5CMzMSs5BYGZWcg4CM7OScxCYmZWcg8DMrOQcBGY1SApJe9Qx3xhJrY2oySwrDgLbKJIWSfqbpDck/VXS3ZJ266Ll/n1X1NgMujJwJD0gaXxXLKtquSdLmtnVy7XsOQisKxwTEVsDuwB/Bn6Ucz1mth4cBNZlImIl8GtgSHubpM0lfV/SHyX9WdJESVukfX0k3SXpNUmvSnpIUjdJvwAGAHemexrnVK+r/ReypHMk/UXSEknHSjpa0nPp8s6vquMqSYvTv6skbV7R//V0GYsl/WPVujr8DOsiaZSkWZKWp/+Oquh7QNIlkv6fpNcl3SepT41lbAXcC+yabo83JO2abqvzJP23pGWSfiVph/Q9PSXdlLa/lq57J0mXAn8H/Dhdzo9rrK/me9O+bSX9LN1WL0v6tqQWSXsDE4GPpMt9rZ7tY5sGB4F1GUlbAscBj1Q0fw/YE9gP2APoB3wz7ftXoBXoC+wEnA9ERJwE/JF0TyMiLu9glTsDPSuW+b+BLwEHkHzZfVPS7um8FwAHp3XsCxwIfCOt+0jgbOATwGCgekiqs8/Q2fbYAbgbuBroDVwJ3C2pd8VsXwROAXYENkvreJ+IeBM4Clicbo+tI2IxcBZwLHAIsCvwV+Ca9G3jgG2B3dJ1TwD+FhEXAA8BZ6TLOaNG6TXfm/bdAKxKt8P+wOHA+IiYn873cLrc7da1fWwTEhH+898G/wGLgDeA10i+IBYDw9I+AW8CH6yY/yPAC+nri4HfAHt0sNy/72S9Y0i+nFrS6W2AAA6qmGc2cGz6+r+Boyv6jgAWpa+vA75b0bdnuqw96vgMY4DWDmo8CXi0qu1h4OT09QPANyr6/gcwrZPP21rVNh84rGJ6F+BdoDvwj8AfgOE1lvUAyZd3R9u25ntJwvptYIuKthOA36evTwZm5v3/pP/W/697hwlhVr9jI2K6pBZgLPCgpCHAamBLYLak9nkFtKSvrwAuBO5L+ydFxHfXY73LIqItfd3+i/XPFf1/A7ZOX+8KvFjR92La1t43u6qvXd91fIbOVK+zfdn9Kqb/VPH6rYp66/EB4P9IWl3R1kbyhf0Lkl/0t0jaDrgJuCAi3q1juTXfm66vB7CkYlt0A15aj5ptE+ShIesyEdEWEXeQfBl9DFhK8mW8T0Rsl/5tG8mBZSLi9Yj414jYHTgG+Jqkw9oX18XlLSb5Ims3IG0DWELyxVfZ167Tz7Ce62xf9svrVXmi1vZ4CTiqoq7tIqJnRLwcEe9GxEURMQQYBXwK+HIny3pvRR2/9yWSPYI+FevrFRH71LNc23Q5CKzLKDEW2B6YHxGrScbtfyBpx3SefpKOSF9/StIeSn5eriAJkPZf+H8Gdl9rJRtuMvANSX3TA7LfJPmlC/Ar4GRJQ9LjHN9qf9O6PsM63APsKemLkrpLOo7kQPpdG1D/n4HekrataJsIXCrpA2ldfdPtj6RDJQ1L99JWkAwZ1bVtO3pvRCwB7gP+XVKv9GD1ByUdUrHc/pI224DPZzlyEFhXuFPSGyRfGpcC4yLimbTvXGAB8IikFcB04ENp3+B0+g2SsfNrI+KBtO8yki/u1yStdQB1A3wbeAx4EngKmJO2ERH3AlcB96e13l/13s4+Q4ciYhnJr+l/BZYB5wCfioil61t8RPwXSZgtTLfJrsAPgakkQ2uvkxykPyh9y84kZ3CtIDmW8CDvBd8Pgc8rue7j6hqr6+y9XyY5qD2P5OD0r0mOTUCy3Z4B/iRpvT+j5UcR3pszMysz7xGYmZWcg8DMrOQcBGZmJecgMDMrucJdUNanT58YOHBg3mWYmRXK7Nmzl0ZE31p9hQuCgQMH8thjj+VdhplZoUiqvsp9DQ8NmZmVnIPAzKzkHARmZiVXuGMEtbz77ru0traycuXKvEsphJ49e9K/f3969OiRdylmtgloiiBobW1lm222YeDAgVTcHtdqiAiWLVtGa2srgwYNyrscM9sENMXQ0MqVK+ndu7dDoA6S6N27t/eezGyNpggCwCGwHrytzKxS0wSBmZltmKY4RlBt4Hl3d+nyFn33k+ucZ+utt+aNN97o0vWamTVCUwaBmVmuLtx23fNs0HKXZ7JYDw11sYjg61//OkOHDmXYsGHceuutACxZsoTRo0ez3377MXToUB566CHa2to4+eST18z7gx/8IOfqzayMvEfQxe644w7mzp3LE088wdKlSxk5ciSjR4/m5ptv5ogjjuCCCy6gra2Nt956i7lz5/Lyyy/z9NNPA/Daa6/lW7yZlZL3CLrYzJkzOeGEE2hpaWGnnXbikEMOYdasWYwcOZLrr7+eCy+8kKeeeoptttmG3XffnYULF3LmmWcybdo0evXqlXf5ZlZCDoIu1tEzoEePHs2MGTPo168fJ510EjfeeCPbb789TzzxBGPGjOGaa65h/PjxDa7WzMxB0OVGjx7NrbfeSltbG6+88gozZszgwAMP5MUXX2THHXfktNNO49RTT2XOnDksXbqU1atX87nPfY5LLrmEOXPm5F2+mZVQUx4jqOd0z6x85jOf4eGHH2bfffdFEpdffjk777wzN9xwA1dccQU9evRg66235sYbb+Tll1/mlFNOYfXq1QBcdtlludVtZuWljoYyNlUjRoyI6gfTzJ8/n7333juniorJ28wsQ5vg6aOSZkfEiFp9HhoyMys5B4GZWck5CMzMSs5BYGZWcg4CM7OScxCYmZVcU15H0OWnbtVxytbVV1/NT37yE4YMGcLixYuZM2cOl156KWeffXbX1mJm1sWaMwhycO2113Lvvfey1VZb8eKLLzJlypSG19DW1kZLS0vD12tmxeahoS4wYcIEFi5cyKc//Wl++ctfMnLkSHr06PG+eRYtWsRee+3F+PHjGTp0KCeeeCLTp0/nox/9KIMHD+bRRx8F4NFHH2XUqFHsv//+jBo1imeffRZIvuTPPvtshg0bxvDhw/nRj34EwMCBA7n44ov52Mc+xm233cbkyZMZNmwYQ4cO5dxzz23shjCzQvIeQReYOHEi06ZN4/e//z19+vTpcL4FCxZw2223MWnSJEaOHMnNN9/MzJkzmTp1Kt/5zneYMmUKe+21FzNmzKB79+5Mnz6d888/n9tvv51Jkybxwgsv8Pjjj9O9e3deffXVNcvt2bMnM2fOZPHixRx88MHMnj2b7bffnsMPP5wpU6Zw7LHHNmArmFlROQgaaNCgQQwbNgyAffbZh8MOOwxJDBs2jEWLFgGwfPlyxo0bx/PPP48k3n33XQCmT5/OhAkT6N49+U+2ww47rFnucccdB8CsWbMYM2YMffv2BeDEE09kxowZDgIz61SmQ0OSjpT0rKQFks6r0b+tpDslPSHpGUmnZFlP3jbffPM1r7t167Zmulu3bqxatQqAf/u3f+PQQw/l6aef5s4772TlypVAcntrSTWXu9VWW62Zx8xsfWUWBJJagGuAo4AhwAmShlTN9hVgXkTsC4wB/l3SZlnVVATLly+nX79+APz85z9f03744YczceLENYFROTTU7qCDDuLBBx9k6dKltLW1MXnyZA455JCG1G1mxZXl0NCBwIKIWAgg6RZgLDCvYp4AtlHyU3dr4FVg1UavOaMHPNfjT3/6EyNGjGDFihV069aNq666innz5q37jalzzjmHcePGceWVV/Lxj398Tfv48eN57rnnGD58OD169OC0007jjDPOeN97d9llFy677DIOPfRQIoKjjz6asWPHdtlnM7PmlNltqCV9HjgyIsan0ycBB0XEGRXzbANMBfYCtgGOi4i7O1uub0PdNbzNzDLk21C/t94abdWpcwQwF9gV2A/4saS1Htwr6XRJj0l67JVXXunqOs3MSi3LIGgFdquY7g8srprnFOCOSCwAXiDZO3ifiJgUESMiYkT7GTFmZtY1sgyCWcBgSYPSA8DHkwwDVfojcBiApJ2ADwELN2RlPmOmft5WZlYpsyCIiFXAGcBvgfnAryLiGUkTJE1IZ7sEGCXpKeB3wLkRsXR919WzZ0+WLVvmL7g6RATLli2jZ8+eeZdiZpuITC8oi4h7gHuq2iZWvF4MHL6x6+nfvz+tra34+EF9evbsSf/+/fMuw8w2EU1xZXGPHj0YNGhQ3mWYmRWSbzpnZlZyDgIzs5JzEJiZlZyDwMys5BwEZmYl5yAwMys5B4GZWck5CMzMSs5BYGZWcg4CM7OScxCYmZWcg8DMrOQcBGZmJecgMDMrOQeBmVnJOQjMzErOQWBmVnIOAjOzknMQmJmVXFM8szh3F26b0XKXZ7NcM7MK3iMwMys5B4GZWck5CMzMSs5BYGZWcg4CM7OScxCYmZWcg8DMrOQcBGZmJecgMDMrOQeBmVnJOQjMzErOQWBmVnIOAjOzknMQmJmVnIPAzKzkHARmZiWXaRBIOlLSs5IWSDqvg3nGSJor6RlJD2ZZj5mZrS2zJ5RJagGuAT4BtAKzJE2NiHkV82wHXAscGRF/lLRjVvVYQfnpb2aZy3KP4EBgQUQsjIh3gFuAsVXzfBG4IyL+CBARf8mwHjMzqyHLIOgHvFQx3Zq2VdoT2F7SA5JmS/pyhvWYmVkNWT68XjXaosb6DwAOA7YAHpb0SEQ8974FSacDpwMMGDAgg1LNzMoryz2CVmC3iun+wOIa80yLiDcjYikwA9i3ekERMSkiRkTEiL59+2ZWsJlZGWUZBLOAwZIGSdoMOB6YWjXPb4C/k9Rd0pbAQcD8DGsyM7MqmQ0NRcQqSWcAvwVagOsi4hlJE9L+iRExX9I04ElgNfAfEfF0VjWZmdnasjxGQETcA9xT1TaxavoK4Ios6zAzs475ymIzs5JzEJiZlZyDwMys5BwEZmYl5yAwMys5B4GZWck5CMzMSs5BYGZWcg4CM7OScxCYmZVcXUEg6YOSNk9fj5F0Vvp0MTMzK7h69whuB9ok7QH8DBgE3JxZVWZm1jD1BsHqiFgFfAa4KiL+Bdglu7LMzKxR6g2CdyWdAIwD7krbemRTkpmZNVK9QXAK8BHg0oh4QdIg4KbsyjIzs0ap63kEETFP0rnAgHT6BeC7WRZmZmaNUe9ZQ8cAc4Fp6fR+kqofO2lmZgVU79DQhcCBwGsAETGX5MwhMzMruHqDYFVELK9qi64uxszMGq/eZxY/LemLQIukwcBZwB+yK8vMzBql3j2CM4F9gLdJLiRbDnw1o5rMzKyB1rlHIKkFmBoRfw9ckH1JZtYQF26b0XKrR5FtU7fOPYKIaAPekpTR/zVmZpaneo8RrASekvR/gTfbGyPirEyqMjOzhqk3CO5O/8zMrMnUe2XxDZI2A/ZMm56NiHezK8vMzBqlriCQNAa4AVgECNhN0riImJFZZWZm1hD1Dg39O3B4RDwLIGlPYDJwQFaFmZlZY9R7HUGP9hAAiIjn8G2ozcyaQr17BI9J+hnwi3T6RGB2NiWZmVkj1RsE/wx8heTWEgJmANdmVZSZmTVOvUHQHfhhRFwJa6423jyzqszMrGHqPUbwO2CLiuktgOldX46ZmTVavUHQMyLeaJ9IX2+ZTUlmZtZI9QbBm5I+3D4haQTwt2xKMjOzRqr3GMFXgdskLSZ5IM2uwHFZFWVmZo3T6R6BpJGSdo6IWcBewK3AKpJnF7/QgPrMzCxj6xoa+inwTvr6I8D5wDXAX4FJ61q4pCMlPStpgaTzOplvpKQ2SZ+vs24zM+si6xoaaomIV9PXxwGTIuJ24HZJczt7Y3qK6TXAJ4BWYJakqRExr8Z83wN+uwH1m5nZRlrXHkGLpPawOAy4v6JvXSFyILAgIhZGxDvALcDYGvOdCdwO/KWOes3MrIut68t8MvCgpKUkZwk9BCBpD5LnFnemH/BSxXQrcFDlDJL6AZ8BPg6MrL9sMzPrKp0GQURcKul3wC7AfRERaVc3kl/ynVGtRVZNXwWcGxFtUq3Z0wVJpwOnAwwYMGAdqzUzs/WxztNHI+KRGm3P1bHsVmC3iun+wOKqeUYAt6Qh0Ac4WtKqiJhStb5JpAenR4wYUR0mZma2Eeq9jmBDzAIGSxoEvAwcD3yxcoaIGNT+WtLPgbuqQ8DMzLKVWRBExCpJZ5CcDdQCXBcRz0iakPZPzGrdZmZWvyz3CIiIe4B7qtpqBkBEnJxlLWZmVlu99xoyM7Mm5SAwMys5B4GZWck5CMzMSs5BYGZWcg4CM7OScxCYmZWcg8DMrOQcBGZmJecgMDMrOQeBmVnJOQjMzErOQWBmVnIOAjOzknMQmJmVnIPAzKzkHARmZiXnIDAzKzkHgZlZyTkIzMxKzkFgZlZyDgIzs5JzEJiZlZyDwMys5BwEZmYl5yAwMys5B4GZWck5CMzMSs5BYGZWcg4CM7OScxCYmZWcg8DMrOQcBGZmJecgMDMrOQeBmVnJOQjMzErOQWBmVnIOAjOzkss0CCQdKelZSQsknVej/0RJT6Z/f5C0b5b1mJnZ2jILAkktwDXAUcAQ4ARJQ6pmewE4JCKGA5cAk7Kqx8zMastyj+BAYEFELIyId4BbgLGVM0TEHyLir+nkI0D/DOsxM7MasgyCfsBLFdOtaVtHTgXurdUh6XRJj0l67JVXXunCEs3MLMsgUI22qDmjdChJEJxbqz8iJkXEiIgY0bdv3y4s0czMume47FZgt4rp/sDi6pkkDQf+AzgqIpZlWI+ZmdWQ5R7BLGCwpEGSNgOOB6ZWziBpAHAHcFJEPJdhLWZm1oHM9ggiYpWkM4DfAi3AdRHxjKQJaf9E4JtAb+BaSQCrImJEVjWZmdnashwaIiLuAe6paptY8Xo8MD7LGszMrHO+stjMrOQcBGZmJecgMDMrOQeBmVnJOQjMzErOQWBmVnIOAjOzknMQmJmVnIPAzKzkHARmZiXnIDAzKzkHgZlZyTkIzMxKzkFgZlZyDgIzs5JzEJiZlZyDwMys5BwEZmYl5yAwMys5B4GZWck5CMzMSs5BYGZWct3zLsDMOjfwvLszWe6inpks1grIewRmZiXnIDAzKzkHgZlZyTkIzMxKzkFgZlZyDgIzs5Lz6aPWJXyKo1lxeY/AzKzkHARmZiXnIDAzK7lSHSPwOLaZ2dq8R2BmVnIOAjOzknMQmJmVXKZBIOlISc9KWiDpvBr9knR12v+kpA9nWY+Zma0tsyCQ1AJcAxwFDAFOkDSkarajgMHp3+nAT7Kqx8zMastyj+BAYEFELIyId4BbgLFV84wFbozEI8B2knbJsCYzM6uS5emj/YCXKqZbgYPqmKcfsKRyJkmnk+wxALwh6dmuLXXjaP1m7wMsrWvOi9ZzyU3I2zY73rabjEZt2w901JFlENSqODZgHiJiEjCpK4rKm6THImJE3nU0I2/b7HjbZmdT2LZZDg21ArtVTPcHFm/APGZmlqEsg2AWMFjSIEmbAccDU6vmmQp8OT176GBgeUQsqV6QmZllJ7OhoYhYJekM4LdAC3BdRDwjaULaPxG4BzgaWAC8BZySVT2bkKYY4tpEedtmx9s2O7lvW0WsNSRvZmYl4iuLzcxKzkFgZlZyDgIzs5Ir1fMIGknSZzvrj4g7GlWLmVlnHATZOaaTvgAcBF1E0g5ARMRf867FrB6SBgOXkdyHbc2jrSJi9zzqcRBkJCLKcCpsbiQNAC4HDgNeS5rUC7gfOC8iFuVXXfGle7TfA3YkuQOASMK2V66FNY/rgW8BPwAOJTl1Prd7c/j00YxI+lpn/RFxZaNqaUaSHgauAn4dEW1pWwvwD8BXI+LgHMsrPEkLgGMiYn7etTQjSbMj4gBJT0XEsLTtoYj4uzzq8R5BdrbJu4Am1ycibq1sSAPhFkmX5FRTM/mzQyBTKyV1A55PL7x9mWTvKxfeI7BCknQL8CpwA+/dwXY3YBxJSHwhr9qKrOIkh0OAnYEpwNvt/T7JoWtIGgnMB7YDLgF6AZdHxH/mUo+DIBuSzomIyyX9iNp3VD0rh7KaRnr/qlNJnmnRj2R8tZXk/lU/i4i3O3m7dUDS9Z10R0T8Y8OKaWKS/iEibltXW8PqcRBkQ9IxEXGnpHG1+iPihkbXZGabBklzIuLD62prFB8jyEgaAi3A0Ij4et71NBtJPYHjSIaH7gK+DowG/hu4JCLqe9CH1STpcuDbwN+AacC+JAfhb8q1sIKTdBTJjTb7Sbq6oqsXsCqfqnxlcWYkdU8PXh6Qdy1N6kbgcJLhoQdInr70Y+B14Oe5VdU8Do+IFcCnSIbc9iQJW9s4i4HHgJXA7Iq/qcAReRXlPYLsPAp8GHhc0lTgNuDN9k4fdNtoQyJiqKTuQGtEHJK2T5P0RJ6FNYke6b9HA5Mj4lXJj6DcWBHxBPCEpJtJvn8HRETuj971HkH2dgCWAR8n+XV1TPqvbZx3IHnuBWs/1a6t8eU0nTsl/RcwAvidpL4kv2KtaxwJzCUZdkPSfukPxlz4YHFGJLUCV5Jekcn7rxoMX1C2cST9BbiFZLsel74mnf5CROyUV23NQtL2wIqIaJO0JdArIv6Ud13NQNJskh+HD0TE/mnbkxExPI96PDSUnRZga2pfNu703XiV49WPVfVVT1udJH08Iu6vvGli1ZCQhzS7xqqIWL6pDLc5CLKzJCIuzruIZtV++m1H52PnU1VTOITkfk21bpromyV2naclfRFoSW9Adxbwh7yK8dBQRiQ93r7LZ9nZ1M7HNqtHOtR2AcmZbyJ5tvslEZHLcRgHQUYk7RARr+ZdR7OqOB/7C0DlPYd6kZxRdGAuhRWcpP7AwIiYmU5/jWSIE+DmiFiQW3GWGQ8NZcQhkLn287E/TXIedrvXgX/JpaLmcAXwy4rpfwImAVsCFwEn5lFUs1jXmUER8elG1VLJewRWaJJ6sAmdj1101cNqlUOced4muVlIeoXkJomTgf+k6mSSiHgwj7p8HYEV3SZ1PnYT6Fk1fVjF696NLKRJ7QycDwwFfgh8AlgaEQ/mFQLgILDiuxA4kOQpZUTEXGBgbtUU3+uS9myfaB/ilLQX8EZuVTWJiGiLiGkRMQ44GFgAPCDpzDzr8jECK7pN6nzsJvAt4C5JlwJz0rYDSH7F/s/cqmoikjYHPgmcQPKj5WpyPi3XQWBFt0mdj110ETEtvZjsHJJtCfAM8NmIeDq/ypqDpBtIhoXuBS7aVLapDxZboW1q52ObdUbSat67+WTll69Ibj3Tq/FVOQjMrIKkjwG7R8SN6fSvSW6cCPDtiLg/t+IsMx4askJKH6nY0a+YiIhTG1lPE7kIqDxw+SHgZGArkuMEDoIm5CCworqrRtsA4KskN/yzDdMrIuZVTD8fEbMBJF2WU02WMQ8NWeFJ2p3k1+po4AckD69/J9+qiknS8xExuIO+BRGxR6Nrsuz5OgIrLEl7S7oJuBOYSXKPoZ84BDbKf0n6ZHWjpE8BvnK7SXmPwApJ0m0kT8/6PvArqp5K5ns9bRhJewB3k5yCW3kdwSjgUxHxXF61WXYcBFZIkhbx3sHi9n/bryqLiNi94UU1AUk/JrkPzoeAfdLmZ0juPOpTcpuUDxZbIUXEwLxraFLPk+xl7UJye+/J6W07rIn5GIEVmqTf1dNm9YmIH0bER0ieVPYqcL2k+ZK+WXkPImsuHhqyQpLUk+Tc9vuBMbw3LNQLuDci9s6ptKYjaX/gOmB4RPjU3CbkoSErqn8iuWZgV5IH07QHwQrgmpxqahrpcx6OBI4nuRX1gyQXm1kT8h6BFZqkMyPiR3nX0SwkfYLkrpifBB4FbgGmRMSbnb7RCs1BYIUnaRTJ7XzX7OG23yvH1o+k3wM3A7f7FNzycBBYoUn6BfBBkqeUtV9LEBFxVodvMrP3cRBYoUmaT3JFsf9HNttAPn3Uiu5pkufAmtkG8llDVnR9gHmSHgXebm+MiE/nV5JZsTgIrOguzLsAs6LzMQIrPEkfAAZHxPT00ZUtEfF63nWZFYWPEVihSToN+DXw07SpHzAlt4LMCshBYEX3FeCjJFcUExHPAzvmWpFZwTgIrOjernwQjaTudPwsYzOrwUFgRfegpPOBLdLbI9xG8sQyM6uTDxZboUnqBpwKHE5y47nfAv/hC8zM6ucgMDMrOV9HYIUk6VcR8QVJT1HjmEBEDM+hLLNC8h6BFZKkXSJiSXoNwVoi4sVG12RWVN4jsEKKiCXpy27AkvYHq0vaAtgpt8LMCshnDVnR3QasrphuS9vMrE4OAiu67pXXEaSvN8uxHrPCcRBY0b0iac2dRiWNBZbmWI9Z4fhgsRWapA8CvyR5iL2Al4AvR8SCXAszKxAHgTUFSVuT/P/su46arScHgRWSpC9FxE2SvlarPyKubHRNZkXl00etqLZM/90m1yrMmoCDwIrqg+m/8yLCp4uabQSfNWRFdbSkHsD/yrsQs6LzHoEV1TSS00S3krSiol1ARESvfMoyKx4fLLZCkrR5RLwt6TcRMTbvesyKzENDVlQPp/+u6HQuM1snDw1ZUW0maRwwStJnqzsj4o4cajIrJAeBFdUE4ERgO+CYqr4AHARmdfIxAis0SadGxM/yrsOsyHyMwApJ0jkAEfEzSf9Q1fedfKoyKyYHgRXV8RWvq68lOLKRhZgVnYPAikodvK41bWadcBBYUUUHr2tNm1knfLDYCklSG/Amya//LYC32ruAnhHRI6/azIrGQWBmVnIeGjIzKzkHgZlZyTkIzFKSQtIvKqa7S3pF0l3ruZxFkvps7DxmjeIgMHvPm8BQSVuk058AXs6xHrOGcBCYvd+9wCfT1ycAk9s7JO0gaYqkJyU9Iml42t5b0n2SHpf0UyquY5D0JUmPSpor6aeSWipXJmkrSXdLekLS05KOy/4jmr2fg8Ds/W4BjpfUExgO/GdF30XA4xExHDgfuDFt/xYwMyL2B6YCAwAk7Q0cB3w0IvYD2khulFfpSGBxROwbEUNJHrhj1lC++6hZhYh4UtJAkr2Be6q6PwZ8Lp3v/nRPYFtgNPDZtP1uSX9N5z8MOACYJQmS6x3+UrXMp4DvS/oecFdEPNT1n8qscw4Cs7VNBb4PjAF6V7TXunVFVP1bScANEdHhc5Uj4jlJBwBHA5dJui8iLt6gqs02kIeGzNZ2HXBxRDxV1T6DdGhH0hhgaUSsqGo/Ctg+nf93wOcl7Zj27SDpA5ULlLQr8FZE3EQSPh/O4gOZdcZ7BGZVIqIV+GGNrguB6yU9SXJLi3Fp+0XAZElzgAeBP6bLmSfpG8B9kroB7wJfAV6sWOYw4ApJq9P+f+76T2TWOd9iwsys5Dw0ZGZWcg4CM7OScxCYmZWcg8DMrOQcBGZmJecgMDMrOQeBmVnJ/X+P07oEXPeX/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = {}\n",
    "loss = {}\n",
    "\n",
    "score['Trill'] = 0.6876\n",
    "score['EfficientNetB0'] = 0.6120\n",
    "score['VGGish'] = 0.4858\n",
    "score['Meta'] = 0.8984\n",
    "\n",
    "loss['Trill'] = 0.0290\n",
    "loss['EfficientNetB0'] = 0.0492\n",
    "loss['VGGish'] = 0.0762\n",
    "loss['Meta'] = 0\n",
    "\n",
    "ind = np.arange(4)\n",
    "width = 0.25\n",
    "plt.bar(ind, loss.values(), width, label='loss')\n",
    "plt.bar(ind + width, score.values(), width, label='f1macro')\n",
    "\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Scores')\n",
    "plt.title('Best model on test set')\n",
    "\n",
    "plt.xticks(ind + width, ['Trill', 'EfficientNetB0', 'VGGish', 'Meta'], rotation=90)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2752c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfp8",
   "language": "python",
   "name": "tfp8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
